{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fold 2 of 20210308 (epoch 8) is the model trained with almost all the data\n",
    "'''\n",
    "TRAIN_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/spgc/views3/\"\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/spgc/views3/\"\n",
    "# TRAIN_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/hmv-hcpa/views66/\"\n",
    "# VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/hmv-hcpa/views66/\"\n",
    "\n",
    "SUB_FILE = ['axis1', 'axis2']\n",
    "# SUB_FILE = ['axis1']\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_HEIGHT = 448\n",
    "IMG_WIDTH = 448\n",
    "IMG_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n",
    "DATA_FOLDER = 'spgc-ternario-tf66/'\n",
    "# DATA_FOLDER = 'spgc-binario-tf66/'\n",
    "LOG_FOLDER = 'logs/' + DATA_FOLDER\n",
    "\n",
    "# TRAINING_FOLDER = 'training/spgc-ternario-tf66/resnet101-ternary_cross/fold{}/'\n",
    "# MODEL_FOLDER = 'models/spgc-ternario-tf66/resnet101-ternary_cross/fold{}/'\n",
    "TRAINING_FOLDER = 'training/spgc-binario-tf66/resnet101-bin_cross/fold{}/'\n",
    "MODEL_FOLDER = 'models/spgc-binario-tf66/resnet101-bin_cross/fold{}/'\n",
    "COLUMN_TARGET = 'ternario'\n",
    "\n",
    "STRUCTURE_DATASET_FOLDER = \"csv/input/\" + DATA_FOLDER\n",
    "OUTPUT_PREDICTED_FOLDER = \"csv/output/\" + DATA_FOLDER\n",
    "# OUTPUT_PREDICTED_FOLDER_TEST = OUTPUT_PREDICTED_FOLDER + \"test/\"\n",
    "\n",
    "TEST_FILE = f'csv/input/{DATA_FOLDER}/test/test1.csv'\n",
    "SAVE_TEST_RESULT = 'test1_binario.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import utilities.plot_metrics as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(folder, search_filter=''):\n",
    "    '''\n",
    "    Get all files (full path) contained in a PATH folder by specified search filter \n",
    "    '''\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_data_set(fold_number, cur_subfile, data_train, data_test):\n",
    "    ''' Creates and returns a dataframe with all the full paths (for slice) for train and test images. \n",
    "    Save it as log. \n",
    "    '''\n",
    "    dfs = []\n",
    "    train_images = {\"id\": [], \"label\": []}\n",
    "    validation_images = {\"id\": [], \"label\": []}\n",
    "    \n",
    "    \n",
    "    TRAIN_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        TRAIN_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "\n",
    "    VALIDATION_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_test.iterrows():\n",
    "        VALIDATION_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "    \n",
    "    df_config = [\n",
    "        (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS_SLICE, train_images),\n",
    "        (VALIDATION_IMG_SRC_FOLDER, VALIDATION_IMG_FOLDERS_SLICE, validation_images)\n",
    "    ]\n",
    "    for (base, folder, dic) in df_config:\n",
    "        for img_folder, img_label in folder.items():\n",
    "            search_folder = \"{}/{}\".format(base, img_folder)\n",
    "            imgs_filename = sorted(get_file_path(search_folder, search_filter = cur_subfile))\n",
    "            dic[\"id\"].extend(imgs_filename)\n",
    "            dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "        dfs.append(pd.DataFrame(data=dic))\n",
    "#     print(dfs)\n",
    "    train_df, validation_df = dfs[0], dfs[1]\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"logs/\"): \n",
    "        os.mkdir(\"logs/\")\n",
    "    if not os.path.exists(LOG_FOLDER): \n",
    "        os.mkdir(LOG_FOLDER)\n",
    "        \n",
    "    train_df.to_csv(\"{}/train{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "    validation_df.to_csv(\"{}/test{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "\n",
    "    print(\"Train fold with {} images\".format(len(train_df)))\n",
    "    print(train_df.groupby(\"label\").label.count())\n",
    "    print()\n",
    "    print(\"Validation fold with {} images\".format(len(validation_df)))\n",
    "    print(validation_df.groupby(\"label\").label.count())\n",
    "    print(\"-\" * 30)\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True, batch_size=32, class_mode=\"binary\"):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    )\n",
    "    \n",
    "    data_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        class_mode=class_mode,\n",
    "        # color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_by_patient(model, patients, legend_file, axis):\n",
    "    results = []\n",
    "    print(legend_file+'.npy')\n",
    "    if os.path.isfile(legend_file+'.npy'):\n",
    "        class_indices = np.load(legend_file+'.npy', allow_pickle=True).item()\n",
    "        class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "    print(class_indices)\n",
    "    for p in patients:\n",
    "        curr_dir = \"{}/{}/{}\".format(VALIDATION_IMG_SRC_FOLDER, p, axis)\n",
    "        imgs_filename = sorted(os.listdir(curr_dir))\n",
    "        test_filenames = imgs_filename[:]\n",
    "        test_df = pd.DataFrame({\n",
    "                'filename': test_filenames\n",
    "            })\n",
    "        nb_samples = test_df.shape[0]\n",
    "\n",
    "        test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_gen.flow_from_dataframe(\n",
    "                test_df, \n",
    "                curr_dir, \n",
    "                x_col='filename',\n",
    "                y_col=None,\n",
    "                class_mode=None,\n",
    "                target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                batch_size=16,\n",
    "                shuffle=False\n",
    "        )\n",
    "\n",
    "        predict = model.predict(test_generator, steps=np.ceil(nb_samples/16))\n",
    "        print(p)\n",
    "        print(predict)\n",
    "        test_df['predicted'] = [np.where(pr == np.max(pr))[0][0] for pr in predict]\n",
    "        for key in class_indices.keys():\n",
    "            t = class_indices[key]\n",
    "            test_df[t] = 0\n",
    "            test_df.loc[test_df['predicted'] == key, t] = 1\n",
    "        test_df['patient'] = p\n",
    "        test_df['axis'] = axis\n",
    "        results.append(test_df)\n",
    "\n",
    "    print('Axis: ', test_df['axis'][0])\n",
    "    df_result = pd.DataFrame()\n",
    "    for i,test_df in enumerate(results):\n",
    "        cur_patient = test_df['patient'][0]\n",
    "        test_df['predicted'] = 0\n",
    "        test_df['patient'] = 0\n",
    "        test_df = test_df.groupby(['patient', 'predicted'], as_index = False).sum()\n",
    "        test_df['predicted'] = test_df.idxmax(axis=1)\n",
    "        test_df['patient'] = cur_patient\n",
    "        df_result = df_result.append(test_df)\n",
    "        \n",
    "    return df_result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models!\n",
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "axis1\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "Fold \n",
      "models/spgc-binario-tf66/resnet101-bin_cross/fold//axis1/legend.npy\n",
      "{0: 'covid', 1: 'normal'}\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Axis:  axis1\n",
      "  patient predicted  covid  normal  fold\n",
      "0  T1-001     covid     42       0     1\n",
      "0  T1-002     covid     42       0     1\n",
      "0  T1-003     covid     42       0     1\n",
      "0  T1-004     covid     42       0     1\n",
      "0  T1-005     covid     42       0     1\n",
      "0  T1-006     covid     42       0     1\n",
      "0  T1-007     covid     42       0     1\n",
      "0  T1-008     covid     42       0     1\n",
      "0  T1-009     covid     42       0     1\n",
      "0  T1-010     covid     42       0     1\n",
      "0  T1-011     covid     42       0     1\n",
      "0  T1-012     covid     42       0     1\n",
      "0  T1-013     covid     42       0     1\n",
      "0  T1-014     covid     42       0     1\n",
      "0  T1-015     covid     42       0     1\n",
      "0  T1-016     covid     42       0     1\n",
      "0  T1-017     covid     42       0     1\n",
      "0  T1-018     covid     42       0     1\n",
      "0  T1-019     covid     42       0     1\n",
      "0  T1-020     covid     42       0     1\n",
      "0  T1-021     covid     42       0     1\n",
      "0  T1-022     covid     42       0     1\n",
      "0  T1-023     covid     42       0     1\n",
      "0  T1-024     covid     42       0     1\n",
      "0  T1-025     covid     42       0     1\n",
      "0  T1-026     covid     42       0     1\n",
      "0  T1-027     covid     42       0     1\n",
      "0  T1-028     covid     42       0     1\n",
      "0  T1-029     covid     42       0     1\n",
      "0  T1-030     covid     42       0     1\n",
      "\n",
      "axis2\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "Fold \n",
      "models/spgc-binario-tf66/resnet101-bin_cross/fold//axis2/legend.npy\n",
      "{0: 'covid', 1: 'normal'}\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Found 42 validated image filenames.\n",
      "Axis:  axis2\n",
      "  patient predicted  covid  normal  fold\n",
      "0  T1-001     covid     42       0     1\n",
      "0  T1-002     covid     42       0     1\n",
      "0  T1-003     covid     42       0     1\n",
      "0  T1-004     covid     42       0     1\n",
      "0  T1-005     covid     42       0     1\n",
      "0  T1-006     covid     42       0     1\n",
      "0  T1-007     covid     42       0     1\n",
      "0  T1-008     covid     42       0     1\n",
      "0  T1-009     covid     42       0     1\n",
      "0  T1-010     covid     42       0     1\n",
      "0  T1-011     covid     42       0     1\n",
      "0  T1-012     covid     42       0     1\n",
      "0  T1-013     covid     42       0     1\n",
      "0  T1-014     covid     42       0     1\n",
      "0  T1-015     covid     42       0     1\n",
      "0  T1-016     covid     42       0     1\n",
      "0  T1-017     covid     42       0     1\n",
      "0  T1-018     covid     42       0     1\n",
      "0  T1-019     covid     42       0     1\n",
      "0  T1-020     covid     42       0     1\n",
      "0  T1-021     covid     42       0     1\n",
      "0  T1-022     covid     42       0     1\n",
      "0  T1-023     covid     42       0     1\n",
      "0  T1-024     covid     42       0     1\n",
      "0  T1-025     covid     42       0     1\n",
      "0  T1-026     covid     42       0     1\n",
      "0  T1-027     covid     42       0     1\n",
      "0  T1-028     covid     42       0     1\n",
      "0  T1-029     covid     42       0     1\n",
      "0  T1-030     covid     42       0     1\n"
     ]
    }
   ],
   "source": [
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=======================================================================================')\n",
    "    \n",
    "    predicted_dir = \"{}/\".format(OUTPUT_PREDICTED_FOLDER)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    predicted_dir = \"{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    \n",
    "    # Predicted class for patient and fold\n",
    "    df_axis = pd.DataFrame()\n",
    "    \n",
    "    for n_fold in ['']: \n",
    "#     for n_fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))        \n",
    "        data_test = pd.read_csv(TEST_FILE)    \n",
    "        model_folder = MODEL_FOLDER.format(n_fold)\n",
    "        training_folder = TRAINING_FOLDER.format(n_fold)\n",
    "        legend_path = \"{}/{}/legend\".format(model_folder, axis)\n",
    "        model = tf.keras.models.load_model(\"{}/{}/my_checkpoint\".format(training_folder, axis))\n",
    "        \n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_test['nome'].head(3).to_list(), legend_path, axis)\n",
    "        df['fold'] = 1\n",
    "        df_axis = df_axis.append(df)\n",
    "    \n",
    "#     save_result_file = SAVE_TEST_RESULT.format(n_fold)\n",
    "    save_result_file = SAVE_TEST_RESULT\n",
    "    predicted_path = \"{}/{}/{}\".format(OUTPUT_PREDICTED_FOLDER, axis, save_result_file)\n",
    "    \n",
    "    df_axis.to_csv(predicted_path, index=False)\n",
    "    print(df_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
