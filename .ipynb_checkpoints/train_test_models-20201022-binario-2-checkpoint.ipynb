{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_TEST = \"exame-pulmao\"\n",
    "TRAIN_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA-tf12-all/\" + FOLDER_TEST\n",
    "# VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-vidro/\" + FOLDER_TEST\n",
    "# VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HCPA-vidro/\" + FOLDER_TEST\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA-tf12-all/\" + FOLDER_TEST\n",
    "\n",
    "# SUB_FILE = ['axis1', 'axis2', 'axis3', 'axis4', 'axis5', 'axis6']\n",
    "SUB_FILE = ['axis1']\n",
    "# SUB_FILE = ['axis3', 'axis4']\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_HEIGHT = 298 # 448\n",
    "IMG_WIDTH = 298 # 448\n",
    "IMG_CHANNELS = 3\n",
    "SELECTED_MODEL = ''\n",
    "NUM_CLASSES = 2\n",
    "DATA_FOLDER = '20201022-2/'\n",
    "LOG_FOLDER = 'logs/' + DATA_FOLDER\n",
    "TRAINING_FOLDER = 'training/' + DATA_FOLDER\n",
    "MODEL_FOLDER = 'models/' + DATA_FOLDER\n",
    "IMAGE_FOLDER = 'images/' + DATA_FOLDER\n",
    "\n",
    "STRUCTURE_DATASET_FOLDER = \"csv/input/\"+DATA_FOLDER\n",
    "OUTPUT_PREDICTED_FOLDER = \"csv/output/\" + DATA_FOLDER\n",
    "LABELS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import utilities.plot_metrics as pm\n",
    "\n",
    "P_REGEX = re.compile('.*[_](2|3|6|7)\\d.*$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(folder, search_filter=''):\n",
    "    '''\n",
    "    Get all files (full path) contained in a PATH folder by specified search filter \n",
    "    '''\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_data_set(fold_number, cur_subfile, data_train, data_test):\n",
    "    ''' Creates and returns a dataframe with all the full paths (for slice) for train and test images. \n",
    "    Save it as log. \n",
    "    '''\n",
    "    dfs = []\n",
    "    train_images = {\"id1\": [], \"id2\": [], \"id4\": [], \"label\": []}\n",
    "    validation_images = {\"id1\": [], \"id2\": [], \"id4\": [], \"label\": []}\n",
    "    \n",
    "    \n",
    "    TRAIN_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        TRAIN_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "\n",
    "    VALIDATION_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_test.iterrows():\n",
    "        VALIDATION_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "    \n",
    "    df_config = [\n",
    "        (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS_SLICE, train_images),\n",
    "        (VALIDATION_IMG_SRC_FOLDER, VALIDATION_IMG_FOLDERS_SLICE, validation_images)\n",
    "    ]\n",
    "    for (base, folder, dic) in df_config:\n",
    "        for img_folder, img_label in folder.items():\n",
    "            search_folder = \"{}/{}\".format(base, img_folder)\n",
    "            imgs_filename = sorted(get_file_path(search_folder, search_filter = cur_subfile))\n",
    "            imgs_filename = [ s for s in imgs_filename if P_REGEX.match(s) ]\n",
    "            dic[\"id1\"].extend(imgs_filename)\n",
    "            dic[\"id2\"].extend([i.replace('axis1', 'axis2').replace('3D_View1', '3D_View2') for i in imgs_filename])\n",
    "            dic[\"id4\"].extend([i.replace('axis1', 'axis4').replace('3D_View1', '3D_View4') for i in imgs_filename])\n",
    "            dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "        dfs.append(pd.DataFrame(data=dic))\n",
    "#     print(dfs)\n",
    "    train_df, validation_df = dfs[0], dfs[1]\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"logs/\"): \n",
    "        os.mkdir(\"logs/\")\n",
    "    if not os.path.exists(LOG_FOLDER): \n",
    "        os.mkdir(LOG_FOLDER)\n",
    "        \n",
    "    train_df.to_csv(\"{}/train{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "    validation_df.to_csv(\"{}/test{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "\n",
    "    print(\"Train fold with {} images\".format(len(train_df)))\n",
    "    print(train_df.groupby(\"label\").label.count())\n",
    "    print()\n",
    "    print(\"Validation fold with {} images\".format(len(validation_df)))\n",
    "    print(validation_df.groupby(\"label\").label.count())\n",
    "    print(\"-\" * 30)\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel=img.shape\n",
    "    if side_type==\"horizontal\":\n",
    "        return np.ones((height,side_size,  channel), dtype=np.float32)*255\n",
    "        \n",
    "    return np.ones((side_size, width,  channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show=\"all\"):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(train_images[\"id\"])\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(train_images[\"label\"])\n",
    "    for path, target in zip(train_images[\"id\"], train_images[\"label\"]):\n",
    "        if target!=show and show!=\"all\":\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        #Image loading from disk as JpegImageFile file format\n",
    "        img=load_img(path, target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "        #Converting JpegImageFile to numpy array\n",
    "        img=img_to_array(img)\n",
    "        \n",
    "        hside=get_side(img, side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if counter%10==0:\n",
    "            himage=np.hstack((images))\n",
    "            vside=get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images=list()\n",
    "\n",
    "    gallery=np.vstack((vertical_images)) \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title = {\"all\":\"All Classifications's\",\n",
    "             \"healthy\":\"Healthy\",\n",
    "             \"covid\":\"Covid-19\"}\n",
    "    plt.title(\"100 Samples of {} Patients of the training set\".format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_gallery(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True, batch_size=32, class_mode=\"binary\"):\n",
    "    global LABELS\n",
    "#     print(f'y_col: {y_col}, mode:{class_mode}')\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    )\n",
    "    \n",
    "    data_generator1 = datagen.flow_from_dataframe(dataframe=dataframe, x_col=x_col+'1', y_col=y_col, subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT), class_mode=class_mode, batch_size=batch_size, shuffle=shuffle\n",
    "        # color_mode=\"rgb\",\n",
    "    )\n",
    "    \n",
    "    data_generator2 = datagen.flow_from_dataframe(dataframe=dataframe, x_col=x_col+'2', y_col=y_col, subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT), class_mode=class_mode, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    data_generator4 = datagen.flow_from_dataframe(dataframe=dataframe, x_col=x_col+'4', y_col=y_col, subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT), class_mode=class_mode, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    LABELS = data_generator1.class_indices\n",
    "#     print(LABELS, data_generator2.class_indices, data_generator3.class_indices, data_generator4.class_indices,\n",
    "#          data_generator5.class_indices, data_generator6.class_indices)\n",
    "    if LABELS != data_generator2.class_indices or LABELS != data_generator4.class_indices:\n",
    "        print(\"\\n\\nLABELS 1\\n\\n\")\n",
    "    \n",
    "    while True:\n",
    "        x_1 = data_generator1.next()\n",
    "        x_2 = data_generator2.next()\n",
    "        x_4 = data_generator4.next()\n",
    "        \n",
    "        yield [x_1[0], x_2[0], x_4[0]], x_1[1]\n",
    "    \n",
    "#     return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(id_label):\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer._name = layer._name + id_label\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    set_trainable = False\n",
    "    for layer in base_model.layers:\n",
    "        if layer._name == 'block1_conv1' + id_label:\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vgg16_chico():\n",
    "    with tf.device('/GPU:0'):\n",
    "#         conv_base = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "#         conv_base = get_base_model()\n",
    "        conv_base_a1 = get_base_model('_a1')\n",
    "        conv_base_a2 = get_base_model('_a2')\n",
    "        conv_base_a4 = get_base_model('_a4')\n",
    "\n",
    "        merged_model = tf.keras.layers.Concatenate()([conv_base_a1.output, conv_base_a2.output,\n",
    "                                               conv_base_a4.output])\n",
    "        \n",
    "        merged_model = tf.keras.layers.GlobalAveragePooling2D()(merged_model)\n",
    "        merged_model = tf.keras.layers.Dense(units = 1024)(merged_model)\n",
    "        merged_model = tf.keras.layers.Dense(units = 1024)(merged_model)\n",
    "#         merged_model = tf.keras.layers.Dense(units = NUM_CLASSES,activation = 'softmax')(merged_model)\n",
    "        \n",
    "#         x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        preds = tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'softmax')(merged_model)\n",
    "#         model.add(tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'sigmoid'))\n",
    "\n",
    "#         model = tf.keras.Model(inputs=[conv_base_a1, conv_base_a2, conv_base_a3, \n",
    "#                                        conv_base_a4, conv_base_a5, conv_base_a6], \n",
    "#                                    outputs=preds)\n",
    "\n",
    "        model = tf.keras.Model(inputs=[conv_base_a1.input, conv_base_a2.input, conv_base_a4.input], \n",
    "                               outputs=preds)\n",
    "    \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return (model, 'vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df, validation_df, epochs, fold, axis):\n",
    "    batch_size = 8\n",
    "    train_generator = get_data_generator(train_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "    validation_generator = get_data_generator(validation_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "\n",
    "#     print(train_generator.class_indices)\n",
    "#     print(validation_generator.class_indices)\n",
    "    print(validation_generator)\n",
    "\n",
    "#     step_size_train = train_generator.n // train_generator.batch_size\n",
    "#     step_size_validation = validation_generator.n // validation_generator.batch_size\n",
    "    \n",
    "    step_size_train = len(train_df) // batch_size\n",
    "    step_size_validation = len(validation_df) // batch_size\n",
    "\n",
    "    if step_size_train == 0:\n",
    "        step_size_train = len(train_df) // 2\n",
    "        step_size_validation = len(validation_df) // 2\n",
    "        \n",
    "        \n",
    "    # callbacks, save each time\n",
    "    # training/20200827/vgg16/fold4/axis2\n",
    "    checkpoint_path = \"training/\"\n",
    "    if not os.path.exists(\"training/\"): \n",
    "        os.mkdir(\"training/\")\n",
    "    checkpoint_path = \"{}/\".format(TRAINING_FOLDER)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/fold{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "    \n",
    "    checkpoint_path = \"{}/{}/fold{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    # Save dict results of history and legend from current model\n",
    "    # models/20200827/vgg16/fold4/axis2/{history|legend}\n",
    "    if not os.path.exists(\"models/\"): \n",
    "        os.mkdir(\"models/\")\n",
    "    \n",
    "    model_dir = \"{}/\".format(MODEL_FOLDER)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}\".format(MODEL_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}/fold{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_dir = \"{}/{}/fold{}/{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "#     checkpoint_path = checkpoint_path + \"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_path = checkpoint_path +\"/my_checkpoint\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 25 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True\n",
    "    )\n",
    "        \n",
    "    history = model.fit(train_generator, # X_Train\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=step_size_validation,\n",
    "        callbacks=cp_callback\n",
    "                       )\n",
    "    \n",
    "    # Save last values\n",
    "#     model.save_weights(checkpoint_dir+\"/my_checkpoint\")\n",
    "    # model.save(checkpoint_dir+\"/my_checkpoint\")\n",
    "    \n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = model_dir + 'history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    \n",
    "    # Save classes\n",
    "#     print(train_generator.class_indices)\n",
    "    print(LABELS)\n",
    "#     np.save(model_dir + 'legend', train_generator.class_indices)\n",
    "    np.save(model_dir + 'legend', LABELS)\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(history, sub_folder, fold, sel_model):\n",
    "    acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    \n",
    "    image_dir = \"images/\"\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/\".format(IMAGE_FOLDER)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(image_dir + 'accuracy', pad_inches=0.1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(image_dir + 'loss', orientation='portrait', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate model for data folders (patients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_by_patient(model, patients, legend_file, axis):\n",
    "    \n",
    "    print('Axis: ', axis)\n",
    "    print(legend_file+'.npy')\n",
    "    print(np.load(legend_file+'.npy', allow_pickle=True).item())\n",
    "    \n",
    "    results = []\n",
    "    for p in patients:\n",
    "        # for axis in SUB_FILE:\n",
    "        curr_dir = \"{}/{}/{}\".format(VALIDATION_IMG_SRC_FOLDER, p, axis)\n",
    "        imgs_filename = sorted(os.listdir(curr_dir))\n",
    "        test_filenames = imgs_filename[:]\n",
    "        test_filenames = [curr_dir + '/' + i for i in test_filenames]\n",
    "        test_filenames = [ s for s in test_filenames if P_REGEX.match(s) ]\n",
    "        test_df = pd.DataFrame({\n",
    "                'id1': test_filenames,\n",
    "                'id2': [i.replace('axis1', 'axis2').replace('3D_View1', '3D_View2') for i in test_filenames],\n",
    "                'id4': [i.replace('axis1', 'axis4').replace('3D_View1', '3D_View4') for i in test_filenames],\n",
    "                'label': [str(i%NUM_CLASSES) for i in range(len(test_filenames))]\n",
    "            })\n",
    "#         print(test_df)\n",
    "        nb_samples = test_df.shape[0]\n",
    "\n",
    "#         test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "#         test_generator = test_gen.flow_from_dataframe(\n",
    "#                 test_df, \n",
    "#                 curr_dir, \n",
    "#                 x_col='filename',\n",
    "#                 y_col=None,\n",
    "#                 class_mode=None,\n",
    "#                 target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "#                 batch_size=16,\n",
    "#                 shuffle=False\n",
    "#         )\n",
    "        test_generator = get_data_generator(test_df, \"id\", \"label\", batch_size=16)\n",
    "        predict = model.predict(test_generator, steps=np.ceil(nb_samples/16))\n",
    "\n",
    "        test_df['predicted'] = [np.where(pr == np.max(pr))[0][0] for pr in predict]\n",
    "        test_df['patient'] = p\n",
    "        test_df['axis'] = axis\n",
    "        results.append(test_df)\n",
    "\n",
    "    df_result = pd.DataFrame(columns=['predicted', 'patient','count'])\n",
    "    for i,test_df in enumerate(results):\n",
    "        cur_patient = test_df['patient'][0]\n",
    "        if os.path.isfile(legend_file+'.npy'):\n",
    "            class_indices = np.load(legend_file+'.npy', allow_pickle=True).item()\n",
    "            class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "            test_df['predicted'] = test_df['predicted'].replace(class_indices)\n",
    "        test_df['count'] = 1\n",
    "        test_df = test_df.groupby('predicted', as_index = False)['count'].count()\n",
    "        test_df['patient'] = cur_patient\n",
    "        df_result = df_result.append(test_df)\n",
    "    return df_result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model for 'axis1...n' and folds [ 1...N ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Fold 1\n",
      "Train fold with 8360 images\n",
      "label\n",
      "covid        3440\n",
      "non covid    4920\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 2040 images\n",
      "label\n",
      "covid         840\n",
      "non covid    1200\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis1\n",
      "=====\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1_a1 (InputLayer)         [(None, 298, 298, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2_a2 (InputLayer)         [(None, 298, 298, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3_a4 (InputLayer)         [(None, 298, 298, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_a1 (Conv2D)        (None, 298, 298, 64) 1792        input_1_a1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_a2 (Conv2D)        (None, 298, 298, 64) 1792        input_2_a2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_a4 (Conv2D)        (None, 298, 298, 64) 1792        input_3_a4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_a1 (Conv2D)        (None, 298, 298, 64) 36928       block1_conv1_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_a2 (Conv2D)        (None, 298, 298, 64) 36928       block1_conv1_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_a4 (Conv2D)        (None, 298, 298, 64) 36928       block1_conv1_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_a1 (MaxPooling2D)   (None, 149, 149, 64) 0           block1_conv2_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_a2 (MaxPooling2D)   (None, 149, 149, 64) 0           block1_conv2_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_a4 (MaxPooling2D)   (None, 149, 149, 64) 0           block1_conv2_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_a1 (Conv2D)        (None, 149, 149, 128 73856       block1_pool_a1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_a2 (Conv2D)        (None, 149, 149, 128 73856       block1_pool_a2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_a4 (Conv2D)        (None, 149, 149, 128 73856       block1_pool_a4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_a1 (Conv2D)        (None, 149, 149, 128 147584      block2_conv1_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_a2 (Conv2D)        (None, 149, 149, 128 147584      block2_conv1_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_a4 (Conv2D)        (None, 149, 149, 128 147584      block2_conv1_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_a1 (MaxPooling2D)   (None, 74, 74, 128)  0           block2_conv2_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_a2 (MaxPooling2D)   (None, 74, 74, 128)  0           block2_conv2_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_a4 (MaxPooling2D)   (None, 74, 74, 128)  0           block2_conv2_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_a1 (Conv2D)        (None, 74, 74, 256)  295168      block2_pool_a1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_a2 (Conv2D)        (None, 74, 74, 256)  295168      block2_pool_a2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_a4 (Conv2D)        (None, 74, 74, 256)  295168      block2_pool_a4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_a1 (Conv2D)        (None, 74, 74, 256)  590080      block3_conv1_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_a2 (Conv2D)        (None, 74, 74, 256)  590080      block3_conv1_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_a4 (Conv2D)        (None, 74, 74, 256)  590080      block3_conv1_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_a1 (Conv2D)        (None, 74, 74, 256)  590080      block3_conv2_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_a2 (Conv2D)        (None, 74, 74, 256)  590080      block3_conv2_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_a4 (Conv2D)        (None, 74, 74, 256)  590080      block3_conv2_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_a1 (MaxPooling2D)   (None, 37, 37, 256)  0           block3_conv3_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_a2 (MaxPooling2D)   (None, 37, 37, 256)  0           block3_conv3_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_a4 (MaxPooling2D)   (None, 37, 37, 256)  0           block3_conv3_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_a1 (Conv2D)        (None, 37, 37, 512)  1180160     block3_pool_a1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_a2 (Conv2D)        (None, 37, 37, 512)  1180160     block3_pool_a2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_a4 (Conv2D)        (None, 37, 37, 512)  1180160     block3_pool_a4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_a1 (Conv2D)        (None, 37, 37, 512)  2359808     block4_conv1_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_a2 (Conv2D)        (None, 37, 37, 512)  2359808     block4_conv1_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_a4 (Conv2D)        (None, 37, 37, 512)  2359808     block4_conv1_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_a1 (Conv2D)        (None, 37, 37, 512)  2359808     block4_conv2_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_a2 (Conv2D)        (None, 37, 37, 512)  2359808     block4_conv2_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_a4 (Conv2D)        (None, 37, 37, 512)  2359808     block4_conv2_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool_a1 (MaxPooling2D)   (None, 18, 18, 512)  0           block4_conv3_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool_a2 (MaxPooling2D)   (None, 18, 18, 512)  0           block4_conv3_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool_a4 (MaxPooling2D)   (None, 18, 18, 512)  0           block4_conv3_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_a1 (Conv2D)        (None, 18, 18, 512)  2359808     block4_pool_a1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_a2 (Conv2D)        (None, 18, 18, 512)  2359808     block4_pool_a2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_a4 (Conv2D)        (None, 18, 18, 512)  2359808     block4_pool_a4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_a1 (Conv2D)        (None, 18, 18, 512)  2359808     block5_conv1_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_a2 (Conv2D)        (None, 18, 18, 512)  2359808     block5_conv1_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_a4 (Conv2D)        (None, 18, 18, 512)  2359808     block5_conv1_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_a1 (Conv2D)        (None, 18, 18, 512)  2359808     block5_conv2_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_a2 (Conv2D)        (None, 18, 18, 512)  2359808     block5_conv2_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_a4 (Conv2D)        (None, 18, 18, 512)  2359808     block5_conv2_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool_a1 (MaxPooling2D)   (None, 9, 9, 512)    0           block5_conv3_a1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool_a2 (MaxPooling2D)   (None, 9, 9, 512)    0           block5_conv3_a2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool_a4 (MaxPooling2D)   (None, 9, 9, 512)    0           block5_conv3_a4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9, 9, 1536)   0           block5_pool_a1[0][0]             \n",
      "                                                                 block5_pool_a2[0][0]             \n",
      "                                                                 block5_pool_a4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1536)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1573888     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,769,602\n",
      "Trainable params: 46,769,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<generator object get_data_generator at 0x7fa2b1180a98>\n",
      "Found 8360 validated image filenames belonging to 2 classes.\n",
      "Found 8360 validated image filenames belonging to 2 classes.\n",
      "Found 8360 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.2688 - accuracy: 0.8828Found 2040 validated image filenames belonging to 2 classes.\n",
      "Found 2040 validated image filenames belonging to 2 classes.\n",
      "Found 2040 validated image filenames belonging to 2 classes.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85490, saving model to training/20201022-2//vgg16/fold1/axis1//my_checkpoint\n",
      "WARNING:tensorflow:From /home/guilherme/Documents/noa/cidia19/jupyter/env-cnn/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: training/20201022-2//vgg16/fold1/axis1//my_checkpoint/assets\n",
      "1045/1045 [==============================] - 1787s 2s/step - loss: 0.2688 - accuracy: 0.8828 - val_loss: 0.5698 - val_accuracy: 0.8549\n",
      "Epoch 2/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9876\n",
      "Epoch 00002: val_accuracy did not improve from 0.85490\n",
      "1045/1045 [==============================] - 1718s 2s/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 1.8593 - val_accuracy: 0.8039\n",
      "Epoch 3/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9935\n",
      "Epoch 00003: val_accuracy did not improve from 0.85490\n",
      "1045/1045 [==============================] - 1729s 2s/step - loss: 0.0334 - accuracy: 0.9935 - val_loss: 1.1226 - val_accuracy: 0.8392\n",
      "Epoch 4/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9929\n",
      "Epoch 00004: val_accuracy improved from 0.85490 to 0.85784, saving model to training/20201022-2//vgg16/fold1/axis1//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201022-2//vgg16/fold1/axis1//my_checkpoint/assets\n",
      "1045/1045 [==============================] - 1719s 2s/step - loss: 0.0318 - accuracy: 0.9929 - val_loss: 1.2784 - val_accuracy: 0.8578\n",
      "Epoch 5/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9952\n",
      "Epoch 00005: val_accuracy did not improve from 0.85784\n",
      "1045/1045 [==============================] - 1717s 2s/step - loss: 0.0285 - accuracy: 0.9952 - val_loss: 1.6084 - val_accuracy: 0.8230\n",
      "Epoch 6/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9964\n",
      "Epoch 00006: val_accuracy did not improve from 0.85784\n",
      "1045/1045 [==============================] - 1715s 2s/step - loss: 0.0179 - accuracy: 0.9964 - val_loss: 1.8682 - val_accuracy: 0.8245\n",
      "Epoch 7/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9947\n",
      "Epoch 00007: val_accuracy did not improve from 0.85784\n",
      "1045/1045 [==============================] - 1716s 2s/step - loss: 0.0284 - accuracy: 0.9947 - val_loss: 1.5512 - val_accuracy: 0.8201\n",
      "Epoch 8/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9974\n",
      "Epoch 00008: val_accuracy did not improve from 0.85784\n",
      "1045/1045 [==============================] - 1715s 2s/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 1.7867 - val_accuracy: 0.8495\n",
      "Epoch 9/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9969\n",
      "Epoch 00009: val_accuracy improved from 0.85784 to 0.86078, saving model to training/20201022-2//vgg16/fold1/axis1//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201022-2//vgg16/fold1/axis1//my_checkpoint/assets\n",
      "1045/1045 [==============================] - 1718s 2s/step - loss: 0.0328 - accuracy: 0.9969 - val_loss: 1.7580 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9969\n",
      "Epoch 00010: val_accuracy did not improve from 0.86078\n",
      "1045/1045 [==============================] - 1715s 2s/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 1.2259 - val_accuracy: 0.8505\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis:  axis1\n",
      "models/20201022-2//vgg16/fold1/axis1/legend.npy\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'match'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8ddfc15c59f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;34m'''  GET DATA  '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Test with other patients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_by_patient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patient'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-dab26c995f43>\u001b[0m in \u001b[0;36mpredictions_by_patient\u001b[0;34m(model, patients, legend_file, axis)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_filename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcurr_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_filenames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         test_df = pd.DataFrame({\n\u001b[1;32m     16\u001b[0m                 \u001b[0;34m'id1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_filenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-dab26c995f43>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_filename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcurr_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtest_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_filenames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         test_df = pd.DataFrame({\n\u001b[1;32m     16\u001b[0m                 \u001b[0;34m'id1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_filenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'match'"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, 1))\n",
    "labels = data_train['covid'].unique()\n",
    "\n",
    "labels.sort()\n",
    "labels_length = len(labels)\n",
    "labels_pos_dict = dict(zip(labels, [i for i in range(labels_length)]))\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    \n",
    "    ''' CREATE PATHS FOR SAVE OUTPUT '''\n",
    "    predicted_dir = \"{}/\".format(OUTPUT_PREDICTED_FOLDER)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    predicted_dir = \"{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    ''''''\n",
    "    \n",
    "    ''' CREATE DATAFRAME AND CONFUSION MATRIX - ACCUMULATED '''\n",
    "    # Predicted class for patient and fold\n",
    "    df_axis = pd.DataFrame(columns=['fold', 'patient', 'real', 'predicted', 'count'])\n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix = np.zeros(labels_length*labels_length).reshape(labels_length, labels_length)\n",
    "    ''''''\n",
    "    \n",
    "    for n_fold in [2, 3, 4, 5]:\n",
    "#     for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_train = pd.read_csv(\"{}/train/train{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        train_df, validation_df = get_data_set(n_fold, axis, data_train, data_validation)\n",
    "        data_validation_dict = dict(zip(data_validation.nome, data_validation.covid))\n",
    "        \n",
    "        print('\\n'+axis+'\\n=====')\n",
    "#         model, SELECTED_MODEL = get_model_vgg16()\n",
    "        model, SELECTED_MODEL = get_model_vgg16_chico()\n",
    "#         model, SELECTED_MODEL = get_model_resnet50()\n",
    "        history = train_model(model, train_df, validation_df, EPOCHS, n_fold, axis)\n",
    "        \n",
    "        #Plot Results\n",
    "        plot_results(history, axis, n_fold, SELECTED_MODEL)\n",
    "        # Load legend\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        \n",
    "        \n",
    "        '''  GET DATA  '''\n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)\n",
    "        idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "        df = df[idx]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df['fold'] = n_fold\n",
    "        df['real'] = ''\n",
    "        last_patient = ''\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            if row['patient'] != last_patient:\n",
    "                df.loc[index, 'real'] = data_validation_dict[row['patient']]\n",
    "                real_label_pos = labels_pos_dict[data_validation_dict[row['patient']]]\n",
    "                pred_label_pos = labels_pos_dict[row['predicted']]\n",
    "                confusion_matrix[real_label_pos][pred_label_pos] += 1\n",
    "            last_patient = row['patient']        \n",
    "        df_axis = df_axis.append(df)\n",
    "        print('curr mat:')\n",
    "        print(confusion_matrix)\n",
    "        '''''' '''''' ''''''\n",
    "        \n",
    "    predicted_dir = \"{}/{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis, SELECTED_MODEL)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    df_axis.to_csv(predicted_dir+'predicted.csv', index=False)\n",
    "    print(labels_pos_dict)\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    '''\n",
    "    PRINT METRICS AND CONFUSION MATRIX\n",
    "    '''\n",
    "    pm.plot_labels_metrics(cm=confusion_matrix, normalize=False, labels=labels, show_zero=False,\n",
    "                title='Metrics', clear_diagonal=False, figsize=(15, 105), output_file=\"metrics.png\"\n",
    "                          )\n",
    "    pm.plot_confusion_matrix(cm=confusion_matrix, normalize=False, labels=labels, show_zero=False,\n",
    "                title=\"Confusion Matrix\", clear_diagonal=False, output_file=\"matrix.png\", figsize=(10, 7)\n",
    "                            )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models!\n",
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HMV + HCPA\n",
    "'''\n",
    "data_train = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, 1))\n",
    "labels = data_train['covid'].unique()\n",
    "\n",
    "labels.sort()\n",
    "labels_length = len(labels)\n",
    "labels_pos_dict = dict(zip(labels, [i for i in range(labels_length)]))\n",
    "\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=======================================================================================')\n",
    "    \n",
    "    predicted_dir = \"{}/\".format(OUTPUT_PREDICTED_FOLDER)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    predicted_dir = \"{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    \n",
    "    \n",
    "    # Predicted class for patient and fold\n",
    "    df_axis = pd.DataFrame(columns=['fold', 'patient', 'real', 'predicted', 'count'])\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix = np.zeros(labels_length*labels_length).reshape(labels_length, labels_length)\n",
    "\n",
    "#     for n_fold in [1]: # [1, 2, 3, 4, 5]:\n",
    "    for n_fold in [j+1 for j in range(5)]:\n",
    "#     for n_fold in [j+31 for j in range(14)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        \n",
    "        data_validation_dict = dict(zip(data_validation.nome, data_validation.covid))\n",
    "        \n",
    "#         model, SELECTED_MODEL = get_model_resnet50()\n",
    "#         model, SELECTED_MODEL = get_model_vgg16()\n",
    "        model, SELECTED_MODEL = get_model_vgg16_chico()\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        \n",
    "        model = tf.keras.models.load_model(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        \n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)\n",
    "        idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "        df = df[idx]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df['fold'] = n_fold\n",
    "        df['real'] = ''\n",
    "        last_patient = ''\n",
    "#         print(labels_pos_dict)\n",
    "#         print(data_validation_dict)\n",
    "        for index, row in df.iterrows():\n",
    "            if row['patient'] != last_patient:\n",
    "                df.loc[index, 'real'] = data_validation_dict[row['patient']]\n",
    "                real_label_pos = labels_pos_dict[data_validation_dict[row['patient']]]\n",
    "                pred_label_pos = labels_pos_dict[row['predicted']]\n",
    "                confusion_matrix[real_label_pos][pred_label_pos] += 1\n",
    "            last_patient = row['patient']        \n",
    "        df_axis = df_axis.append(df)\n",
    "        del model\n",
    "    print(df_axis)\n",
    "        \n",
    "    predicted_dir = \"{}/{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis, SELECTED_MODEL)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    df_axis.to_csv(predicted_dir+'predicted.csv', index=False)\n",
    "    print(labels_pos_dict)\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    '''\n",
    "    PRINT METRICS AND CONFUSION MATRIX\n",
    "    '''\n",
    "    pm.plot_labels_metrics(\n",
    "                cm=confusion_matrix,\n",
    "                normalize=False,\n",
    "                labels=labels,\n",
    "                show_zero=False,\n",
    "                title='Metrics - ' + axis,\n",
    "                clear_diagonal=False,\n",
    "                figsize=(15, 105),\n",
    "                output_file=\"metrics.png\"\n",
    "            )\n",
    "    pm.plot_confusion_matrix(\n",
    "                cm=confusion_matrix,\n",
    "                normalize=False,\n",
    "                labels=labels,\n",
    "                show_zero=False,\n",
    "                title=\"Confusion Matrix - \" + axis,\n",
    "                clear_diagonal=False,\n",
    "                output_file=\"matrix.png\",\n",
    "                figsize=(10, 7)\n",
    "#                 verbose=args.verbose,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, SELECTED_MODEL = get_model_resnet50()\n",
    "model, SELECTED_MODEL = get_model_vgg16()\n",
    "\n",
    "# model.load_weights('training/resnet50/5fold/axis1/my_checkpoint')\n",
    "fold = 1\n",
    "axis = 'axis1'\n",
    "legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "model.load_weights(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, fold, axis))\n",
    "\n",
    "# data_test =  ['C77', 'C117', 'C136', 'C80', 'C91', 'C104', 'C62', 'C147', 'C106', 'C68', 'C123', 'C99', 'C129']\n",
    "# HCPA\n",
    "# data_test = ['NEG-001', 'NEG-002', 'NEG-003', 'NEG-004', 'NEG-005', 'NEG-006', 'NEG-007', 'NEG-008', 'NEG-009', \n",
    "#              'NEG-010', 'NEG-011', 'NEG-012', 'NEG-013', 'NEG-014', 'NEG-015', 'TYP-002', 'TYP-003', 'TYP-004', \n",
    "#              'TYP-005', 'TYP-006', 'TYP-007', 'TYP-008', 'TYP-009', 'TYP-010', 'TYP-011', 'TYP-012', 'TYP-013', \n",
    "#              'TYP-014', 'TYP-015', 'TYP-016', 'TYP-017', 'TYP-018', 'TYP-019', 'TYP-020', 'TYP-021', 'TYP-022', \n",
    "#              'TYP-023', 'TYP-024', 'TYP-025', 'TYP-026', 'TYP-027', 'TYP-028', 'TYP-029', 'TYP-030', 'TYP-031']\n",
    "\n",
    "# HMV - CT Indeterminados - PCR Negativo\n",
    "# data_test = ['C8', 'C28', 'C30', 'C31', 'C34', 'C37', 'C38', 'C45', 'C47', 'C54', 'C68', 'C72', 'C84', 'C98', \n",
    "#              'C99', 'C109', 'C119', 'C123', 'C129', 'C139', 'C140', 'C148', 'C156']\n",
    "\n",
    "# HMV - CT Indeterminados - PCR Positivo\n",
    "# data_test = ['C40', 'C48', 'C57', 'C65', 'C97', 'C107', 'C128']\n",
    "\n",
    "# HMV - Atpicos\n",
    "# data_test = ['C9', 'C43', 'C55', 'C56', 'C58', 'C59', 'C64', 'C67', 'C70', 'C73', 'C81', 'C118', 'C122', 'C127', \n",
    "#              'C134', 'C141', 'C164']\n",
    "\n",
    "# HMV - CT Tpico - PCR negativo\n",
    "# data_test = ['C71', 'C101', 'C143', 'C162'] \n",
    "\n",
    "# HMV - CT Negativo - PCR positivo\n",
    "data_test = ['C76', 'C105']\n",
    "\n",
    "# VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HCPA/exame-pulmao\"\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV/exame-pulmao\"\n",
    "\n",
    "df = predictions_by_patient(model, data_test, legend_path, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HCPA\n",
    "'''\n",
    "data_test = ['NEG-001', 'NEG-002', 'NEG-003', 'NEG-004', 'NEG-005', 'NEG-006', 'NEG-007', 'NEG-008', 'NEG-009', \n",
    "             'NEG-010', 'NEG-011', 'NEG-012', 'NEG-013', 'NEG-014', 'NEG-015', 'TYP-002', 'TYP-003', 'TYP-004', \n",
    "             'TYP-005', 'TYP-006', 'TYP-007', 'TYP-008', 'TYP-009', 'TYP-010', 'TYP-011', 'TYP-012', 'TYP-013', \n",
    "             'TYP-014', 'TYP-015', 'TYP-016', 'TYP-017', 'TYP-018', 'TYP-019', 'TYP-020', 'TYP-021', 'TYP-022', \n",
    "             'TYP-023', 'TYP-024', 'TYP-025', 'TYP-026', 'TYP-027', 'TYP-028', 'TYP-029', 'TYP-030', 'TYP-031']\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=====')\n",
    "    for n_fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))        \n",
    "#         model, SELECTED_MODEL = get_model_resnet50()\n",
    "        model, SELECTED_MODEL = get_model_vgg16()\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        model.load_weights(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        \n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_test, legend_path, axis)\n",
    "        idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "        print(df[idx][['category', 'patient', 'count']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=====')\n",
    "    for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))        \n",
    "        #model, SELECTED_MODEL = get_model_resnet50()\n",
    "        SELECTED_MODEL = 'vgg16'\n",
    "        df = pd.read_csv(\"{}/{}/fold{}/{}/history.csv\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        print(max(df['val_accuracy']))\n",
    "        print((df['val_accuracy'].mean()))\n",
    "#         print(df['val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
