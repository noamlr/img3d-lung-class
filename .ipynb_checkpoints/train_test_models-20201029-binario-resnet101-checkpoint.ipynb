{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_TEST = \"exame-pulmao\"\n",
    "TRAIN_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA-tf12-all/\" + FOLDER_TEST\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA-tf12-all/\" + FOLDER_TEST\n",
    "\n",
    "SUB_FILE = ['axis2', 'axis4']\n",
    "# SUB_FILE = ['axis1']\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_HEIGHT = 448\n",
    "IMG_WIDTH = 448\n",
    "IMG_CHANNELS = 3\n",
    "SELECTED_MODEL = ''\n",
    "NUM_CLASSES = 2\n",
    "DATA_FOLDER = '20201029/'\n",
    "LOG_FOLDER = 'logs/' + DATA_FOLDER\n",
    "TRAINING_FOLDER = 'training/' + DATA_FOLDER\n",
    "MODEL_FOLDER = 'models/' + DATA_FOLDER\n",
    "IMAGE_FOLDER = 'images/' + DATA_FOLDER\n",
    "\n",
    "STRUCTURE_DATASET_FOLDER = \"csv/input/\"+DATA_FOLDER\n",
    "OUTPUT_PREDICTED_FOLDER = \"csv/output/\" + DATA_FOLDER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import utilities.plot_metrics as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(folder, search_filter=''):\n",
    "    '''\n",
    "    Get all files (full path) contained in a PATH folder by specified search filter \n",
    "    '''\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_data_set(fold_number, cur_subfile, data_train, data_test):\n",
    "    ''' Creates and returns a dataframe with all the full paths (for slice) for train and test images. \n",
    "    Save it as log. \n",
    "    '''\n",
    "    dfs = []\n",
    "    train_images = {\"id\": [], \"label\": []}\n",
    "    validation_images = {\"id\": [], \"label\": []}\n",
    "    \n",
    "    \n",
    "    TRAIN_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        TRAIN_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "\n",
    "    VALIDATION_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_test.iterrows():\n",
    "        VALIDATION_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "    \n",
    "    df_config = [\n",
    "        (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS_SLICE, train_images),\n",
    "        (VALIDATION_IMG_SRC_FOLDER, VALIDATION_IMG_FOLDERS_SLICE, validation_images)\n",
    "    ]\n",
    "    for (base, folder, dic) in df_config:\n",
    "        for img_folder, img_label in folder.items():\n",
    "            search_folder = \"{}/{}\".format(base, img_folder)\n",
    "            imgs_filename = sorted(get_file_path(search_folder, search_filter = cur_subfile))\n",
    "            dic[\"id\"].extend(imgs_filename)\n",
    "            dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "        dfs.append(pd.DataFrame(data=dic))\n",
    "#     print(dfs)\n",
    "    train_df, validation_df = dfs[0], dfs[1]\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"logs/\"): \n",
    "        os.mkdir(\"logs/\")\n",
    "    if not os.path.exists(LOG_FOLDER): \n",
    "        os.mkdir(LOG_FOLDER)\n",
    "        \n",
    "    train_df.to_csv(\"{}/train{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "    validation_df.to_csv(\"{}/test{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "\n",
    "    print(\"Train fold with {} images\".format(len(train_df)))\n",
    "    print(train_df.groupby(\"label\").label.count())\n",
    "    print()\n",
    "    print(\"Validation fold with {} images\".format(len(validation_df)))\n",
    "    print(validation_df.groupby(\"label\").label.count())\n",
    "    print(\"-\" * 30)\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel=img.shape\n",
    "    if side_type==\"horizontal\":\n",
    "        return np.ones((height,side_size,  channel), dtype=np.float32)*255\n",
    "        \n",
    "    return np.ones((side_size, width,  channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show=\"all\"):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(train_images[\"id\"])\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(train_images[\"label\"])\n",
    "    for path, target in zip(train_images[\"id\"], train_images[\"label\"]):\n",
    "        if target!=show and show!=\"all\":\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        #Image loading from disk as JpegImageFile file format\n",
    "        img=load_img(path, target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "        #Converting JpegImageFile to numpy array\n",
    "        img=img_to_array(img)\n",
    "        \n",
    "        hside=get_side(img, side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if counter%10==0:\n",
    "            himage=np.hstack((images))\n",
    "            vside=get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images=list()\n",
    "\n",
    "    gallery=np.vstack((vertical_images)) \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title = {\"all\":\"All Classifications's\",\n",
    "             \"healthy\":\"Healthy\",\n",
    "             \"covid\":\"Covid-19\"}\n",
    "    plt.title(\"100 Samples of {} Patients of the training set\".format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_gallery(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True, batch_size=32, class_mode=\"binary\"):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    )\n",
    "    \n",
    "    data_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        class_mode=class_mode,\n",
    "        # color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    base_model = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_resnet101v2():\n",
    "    with tf.device('/GPU:0'):\n",
    "        conv_base = get_base_model()\n",
    "        conv_base.trainable = True\n",
    "        \n",
    "#         set_trainable = False\n",
    "#         for layer in conv_base.layers:\n",
    "#             if layer.name == 'block1_conv1':\n",
    "#                 set_trainable = True\n",
    "#             if set_trainable:\n",
    "#                 layer.trainable = True\n",
    "#             else:\n",
    "#                 layer.trainable = False\n",
    "\n",
    "        x = conv_base.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        '''Added'''\n",
    "        x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        preds = tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'softmax')(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=conv_base.input, outputs=preds)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5),\n",
    "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return (model, 'resnet101v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df, validation_df, epochs, fold, axis):\n",
    "    batch_size = 8\n",
    "    train_generator = get_data_generator(train_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "    validation_generator = get_data_generator(validation_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "\n",
    "    print(train_generator.class_indices)\n",
    "    print(validation_generator.class_indices)\n",
    "    \n",
    "    step_size_train = train_generator.n // train_generator.batch_size\n",
    "    step_size_validation = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "    if step_size_train == 0:\n",
    "        step_size_train = train_generator.n // 2\n",
    "        step_size_validation = validation_generator.n // 2\n",
    "        \n",
    "        \n",
    "    # callbacks, save each time\n",
    "    # training/20200827/vgg16/fold4/axis2\n",
    "    checkpoint_path = \"training/\"\n",
    "    if not os.path.exists(\"training/\"): \n",
    "        os.mkdir(\"training/\")\n",
    "    checkpoint_path = \"{}/\".format(TRAINING_FOLDER)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/fold{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "    \n",
    "    checkpoint_path = \"{}/{}/fold{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    # Save dict results of history and legend from current model\n",
    "    # models/20200827/vgg16/fold4/axis2/{history|legend}\n",
    "    if not os.path.exists(\"models/\"): \n",
    "        os.mkdir(\"models/\")\n",
    "    \n",
    "    model_dir = \"{}/\".format(MODEL_FOLDER)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}\".format(MODEL_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}/fold{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_dir = \"{}/{}/fold{}/{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "#     checkpoint_path = checkpoint_path + \"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_path = checkpoint_path +\"/my_checkpoint\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 25 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True\n",
    "    )\n",
    "        \n",
    "    history = model.fit(train_generator, # X_Train\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=step_size_validation,\n",
    "        callbacks=cp_callback\n",
    "                       )\n",
    "    \n",
    "    # Save last values\n",
    "#     model.save_weights(checkpoint_dir+\"/my_checkpoint\")\n",
    "    # model.save(checkpoint_dir+\"/my_checkpoint\")\n",
    "    \n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = model_dir + 'history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    \n",
    "    # Save classes\n",
    "    print(train_generator.class_indices)\n",
    "    np.save(model_dir + 'legend', train_generator.class_indices)\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(history, sub_folder, fold, sel_model):\n",
    "    acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    \n",
    "    image_dir = \"images/\"\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/\".format(IMAGE_FOLDER)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(image_dir + 'accuracy', pad_inches=0.1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(image_dir + 'loss', orientation='portrait', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate model for data folders (patients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_by_patient(model, patients, legend_file, axis):\n",
    "    results = []\n",
    "    for p in patients:\n",
    "        # for axis in SUB_FILE:\n",
    "        curr_dir = \"{}/{}/{}\".format(VALIDATION_IMG_SRC_FOLDER, p, axis)\n",
    "        imgs_filename = sorted(os.listdir(curr_dir))\n",
    "        test_filenames = imgs_filename[:]\n",
    "        test_df = pd.DataFrame({\n",
    "                'filename': test_filenames\n",
    "            })\n",
    "        nb_samples = test_df.shape[0]\n",
    "\n",
    "        test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_gen.flow_from_dataframe(\n",
    "                test_df, \n",
    "                curr_dir, \n",
    "                x_col='filename',\n",
    "                y_col=None,\n",
    "                class_mode=None,\n",
    "                target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                batch_size=16,\n",
    "                shuffle=False\n",
    "        )\n",
    "\n",
    "        predict = model.predict(test_generator, steps=np.ceil(nb_samples/16))\n",
    "\n",
    "        test_df['predicted'] = [np.where(pr == np.max(pr))[0][0] for pr in predict]\n",
    "        test_df['patient'] = p\n",
    "        test_df['axis'] = axis\n",
    "        results.append(test_df)\n",
    "\n",
    "    print('Axis: ', test_df['axis'][0])\n",
    "    df_result = pd.DataFrame(columns=['predicted', 'patient','count'])\n",
    "    for i,test_df in enumerate(results):\n",
    "        cur_patient = test_df['patient'][0]\n",
    "        if os.path.isfile(legend_file+'.npy'):\n",
    "            class_indices = np.load(legend_file+'.npy', allow_pickle=True).item()\n",
    "            class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "            test_df['predicted'] = test_df['predicted'].replace(class_indices)\n",
    "        test_df['count'] = 1\n",
    "        test_df = test_df.groupby('predicted', as_index = False)['count'].count()\n",
    "        test_df['patient'] = cur_patient\n",
    "        df_result = df_result.append(test_df)\n",
    "    return df_result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model for 'axis1...n' and folds [ 1...N ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Train fold with 17302 images\n",
      "label\n",
      "covid         7134\n",
      "non covid    10168\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 4264 images\n",
      "label\n",
      "covid        1804\n",
      "non covid    2460\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis1\n",
      "=====\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 448, 448, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 454, 454, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 224, 224, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 224, 224, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 224, 224, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 226, 226, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 112, 112, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 112, 112, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 112, 112, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 112, 112, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 112, 112, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 112, 112, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 112, 112, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 112, 112, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 112, 112, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 112, 112, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 112, 112, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 112, 112, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 112, 112, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 112, 112, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 112, 112, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 56, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 56, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 56, 56, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 56, 56, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 56, 56, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 56, 56, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 56, 56, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 56, 56, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 56, 56, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 56, 56, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 56, 56, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 56, 56, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 56, 56, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 56, 56, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 56, 56, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 56, 56, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 56, 56, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 56, 56, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 28, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 28, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 28, 28, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 28, 28, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 28, 28, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 28, 28, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 28, 28, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 28, 28, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 28, 28, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 28, 28, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 28, 28, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 28, 28, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 28, 28, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 28, 28, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 28, 28, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 28, 28, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 28, 28, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 28, 28, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 28, 28, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 28, 28, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 28, 28, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 28, 28, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 28, 28, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 28, 28, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 28, 28, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 28, 28, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 28, 28, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 28, 28, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 28, 28, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 28, 28, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 28, 28, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 28, 28, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 28, 28, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 28, 28, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 28, 28, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 28, 28, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 28, 28, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 28, 28, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 28, 28, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 28, 28, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 28, 28, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 28, 28, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 28, 28, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 28, 28, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 28, 28, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 28, 28, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 28, 28, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 28, 28, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 28, 28, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 28, 28, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 28, 28, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 28, 28, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 28, 28, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 28, 28, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 28, 28, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 28, 28, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 28, 28, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 28, 28, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 28, 28, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 28, 28, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 28, 28, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 28, 28, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 28, 28, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 28, 28, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 14, 512)  524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 14, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 14, 14, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 14, 14, 2048) 2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 14, 14, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 14, 14, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 14, 14, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 14, 14, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 14, 14, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 14, 14, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 14, 14, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 14, 14, 2048) 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024)         4096        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 45,812,098\n",
      "Trainable params: 45,704,706\n",
      "Non-trainable params: 107,392\n",
      "__________________________________________________________________________________________________\n",
      "Found 17302 validated image filenames belonging to 2 classes.\n",
      "Found 4264 validated image filenames belonging to 2 classes.\n",
      "{'covid': 0, 'non covid': 1}\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9292\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87711, saving model to training/20201029//resnet101v2/fold4/axis1//my_checkpoint\n",
      "WARNING:tensorflow:From /home/guilherme/Documents/noa/cidia19/jupyter/env-cnn/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold4/axis1//my_checkpoint/assets\n",
      "2162/2162 [==============================] - 2550s 1s/step - loss: 0.1777 - accuracy: 0.9292 - val_loss: 0.5080 - val_accuracy: 0.8771\n",
      "Epoch 2/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9758\n",
      "Epoch 00002: val_accuracy did not improve from 0.87711\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0740 - accuracy: 0.9758 - val_loss: 0.3982 - val_accuracy: 0.8647\n",
      "Epoch 3/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9851\n",
      "Epoch 00003: val_accuracy improved from 0.87711 to 0.89939, saving model to training/20201029//resnet101v2/fold4/axis1//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold4/axis1//my_checkpoint/assets\n",
      "2162/2162 [==============================] - 2553s 1s/step - loss: 0.0453 - accuracy: 0.9851 - val_loss: 0.3983 - val_accuracy: 0.8994\n",
      "Epoch 4/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9904\n",
      "Epoch 00004: val_accuracy did not improve from 0.89939\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.4327 - val_accuracy: 0.8652\n",
      "Epoch 5/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9941\n",
      "Epoch 00005: val_accuracy did not improve from 0.89939\n",
      "2162/2162 [==============================] - 2533s 1s/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.2741 - val_accuracy: 0.8987\n",
      "Epoch 6/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9942\n",
      "Epoch 00006: val_accuracy did not improve from 0.89939\n",
      "2162/2162 [==============================] - 2523s 1s/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.4237 - val_accuracy: 0.8785\n",
      "Epoch 7/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9949\n",
      "Epoch 00007: val_accuracy did not improve from 0.89939\n",
      "2162/2162 [==============================] - 2521s 1s/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.5380 - val_accuracy: 0.8743\n",
      "Epoch 8/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 00008: val_accuracy did not improve from 0.89939\n",
      "2162/2162 [==============================] - 2521s 1s/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.4069 - val_accuracy: 0.8945\n",
      "Epoch 9/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9956\n",
      "Epoch 00009: val_accuracy did not improve from 0.89939\n",
      "2162/2162 [==============================] - 2522s 1s/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.5391 - val_accuracy: 0.8652\n",
      "Epoch 10/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 00010: val_accuracy improved from 0.89939 to 0.91604, saving model to training/20201029//resnet101v2/fold4/axis1//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold4/axis1//my_checkpoint/assets\n",
      "2162/2162 [==============================] - 2554s 1s/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3642 - val_accuracy: 0.9160\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzN9f7A8dd77MNQoZJdWSIMRopbKXVvWmjhV5poriJaUUoRIrm3VG5J92qjTHcqdaW0K1dy3SzJErrIMoksYYQs8/798TnDMWY5M2f5nnPm/Xw85jHnfM/3fL7v8zXe5/v9rKKqGGOMiX0JXgdgjDEmNCyhG2NMnLCEbowxccISujHGxAlL6MYYEycsoRtjTJywhG7yJCIficgtod7XSyKyXkQuDUO5s0XkNt/jVBH5NJB9i3GcOiKyV0RKFTfWAspWETkr1OWayLKEHkd8/9lzfrJFZL/f89SilKWqnVV1Sqj3jUYiMkRE5uSxvZqIHBSRcwItS1XTVfWPIYrruC8gVd2oqpVU9UgoyjfxxxJ6HPH9Z6+kqpWAjcDVftvSc/YTkdLeRRmVpgLtRaR+ru03AstUdbkHMRlTZJbQSwAR6SgimSLyoIhsAV4VkZNF5AMR2SYiv/oe1/J7j381QpqIzBWRcb59fxSRzsXct76IzBGRLBH5XESeF5Gp+cQdSIyjReRrX3mfikg1v9d7isgGEdkhIkPzOz+qmgl8AfTM9VIv4LXC4sgVc5qIzPV7fpmIrBKR3SIyARC/184UkS988W0XkXQROcn32utAHeB93x3WAyJSz1c1Utq3zxkiMkNEdorIGhHp41f2SBF5S0Re852bFSKSkt85yPUZqvjet813/oaJSILvtbNE5N++z7NdRN70bRcReUZEfhGRPSKyrCh3NiY0LKGXHKcDpwB1gb64f/tXfc/rAPuBCQW8vx2wGqgGPAG8LCJSjH3fAL4BqgIjOTGJ+gskxpuAPwOnAmWB+wFEpCnwgq/8M3zHyzMJ+0zxj0VEGgPJvniLeq5yyqgGvAsMw52LtUAH/12Asb74zgZq484JqtqT4++ynsjjEBlApu/93YDHReQSv9e7+PY5CZgRSMw+zwFVgAbARbgvtj/7XhsNfAqcjDufz/m2/xG4EGjke+//ATsCPJ4JFVW1nzj8AdYDl/oedwQOAuUL2D8Z+NXv+WzgNt/jNGCN32uJgAKnF2VfXDI8DCT6vT4VmBrgZ8orxmF+z+8APvY9Hg5k+L1W0XcOLs2n7ERgD9De93wM8F4xz9Vc3+NewHy//QSXgG/Lp9xrgG/z+jf0Pa/nO5elccn/CJDk9/pYYLLv8Ujgc7/XmgL7Czi3CpwFlPKdp6Z+r90OzPY9fg2YBNTK9f5LgB+A84AEr//+S+qPXaGXHNtU9UDOExFJFJF/+G6p9wBzgJMk/x4UW3IeqOo+38NKRdz3DGCn3zaATfkFHGCMW/we7/OL6Qz/slX1Nwq4YvTF9DbQy3c3kYpLXsU5Vzlyx6D+z0XkNBHJEJGffOVOxV3JByLnXGb5bdsA1PR7nvvclJfC20+qAWV8ZeVV7gO4L6ZvfNU4vX2f7QvcHcDzwC8iMklEKgf4WUyIWEIvOXJPq3kf0Bhop6qVcbfL4FfHGwY/A6eISKLfttoF7B9MjD/7l+07ZtVC3jMFV1VwGZAEvB9kHLljEI7/vI/j/l2a+8q9OVeZBU2Fuhl3LpP8ttUBfiokpsJsBw7hqpdOKFdVt6hqH1U9A3flPlF83R1V9VlVbYO7G2gEDA4yFlNEltBLriRcXfAuETkFGBHuA6rqBmAhMFJEyorI+cDVYYpxGnCViPxBRMoCoyj87/0rYBeuSiFDVQ8GGcdMoJmIXOe7Mr4HV/WUIwnYC+wWkZqcmAC34uqxT6Cqm4B5wFgRKS8iLYBbcVf5xaauS+RbwBgRSRKRusCgnHJFpLtfg/CvuC+dbBFpKyLtRKQM8BtwAMgOJhZTdJbQS67xQAXcFdl84OMIHTcVOB9X/fEY8Cbwez77FjtGVV0B3Ilr1PwZl3wyC3mP4qpZ6vp+BxWHqm4HugN/wX3ehsDXfrs8CrQGduOS/7u5ihgLDBORXSJyfx6H6IGrV98M/AsYoaqfBxJbIe7GJeV1wFzcOXzF91pb4L8ishfX0Hqvqq4DKgMv4s7zBtznfTIEsZgiEF+DhjGe8HV7W6WqYb9DMCbe2RW6iSjfrfmZIpIgIpcDXYHpXsdlTDywEYMm0k7HVS1UxVWB9FfVb70NyZj4YFUuxhgTJ6zKxRhj4oRnVS7VqlXTevXqeXV4Y4yJSYsWLdquqtXzes2zhF6vXj0WLlzo1eGNMSYmiciG/F6zKhdjjIkTltCNMSZOWEI3xpg4YQndGGPihCV0Y4yJE5bQjTEmTlhCN8aYOGEJ3Zg4dviw1xFEjw8+gDVrvI4ivCyhGxOHVOH22+HMM+GXX7yOxnuzZsHVV8P110N2HC+7YQndmDg0YQJMmgQbN8Jtt7kEX1Lt2gVpaVC5MixdCm+95XVE4WMJ3Zg4M3s2DBwIXbvCU0/B++/DSy95HZV37roLtmyBzz6D5s3hkUfg0CGvowoPS+jGxJGNG6F7d2jYEF57DQYMgE6d3O///c/r6CLvzTchPd0l8XPPhTFjXD365MleRxYens2HnpKSojY5lzGhs38//OEPLmF98w00buy2Z2a6K9PGjWHuXChdQpa1+ekn97kbNoSvv3afWxXat4dNm9x5Kl/e6yiLTkQWqWpKXq/ZFboxcUAV+vaFb7+FN944lswBatWCv/8d/vtfd4VaEqhC795w4AC8/vqxLzERePxxl+xfeMHbGMPBEroxcWD8eJg6FUaNgiuvPPH1G26A1FQYPdol9ng3cSJ8+qlrQ2jU6PjXLr4YLrvMJfasLG/iCxdL6MbEuFmzYPBguO46ePjh/PebMAFq1oSbb4a9eyMXX6StXu3Ox+WXQ79+ee8zZgxs3w7PPBPZ2MLNEroxMWz9enf13bixa+hLKOB/9EknuYbStWvhvvsiFWFkHToEPXtChQrwyiuuiiUvbdvCtdfCuHGwY0dkYwwnS+jGxKh9++Caa+DIEXjvPUhKKvw9F10E99/v+qi//374Y4y0MWNgwQL4xz+gRo2C9x092t2p/PWvkYktEmIuoau6rlnGlGSqcOutbqDMP/8JZ50V+HtHj4aWLd2Ao3gaRfrNN/DYY+4KvVu3wvdv1szt+9xzrpE0HsRcQv/LX9wf4+rVXkdijHeeegoyMlzD3uWXF+295cq5BtTdu+NnFOm+fS45n3GGS9CBGjnS3eE89ljYQouogBK6iFwuIqtFZI2IDMnj9TQR2SYiS3w/t4U+VOemm6BsWTcvw86d4TqKMdHrs8/gwQfdAKIHHyxeGeec4y6O4mUU6QMPwA8/wJQpUKVK4O+rXx/69HHnYO3a8MUXMapa4A9QClgLNADKAt8BTXPtkwZMKKws/582bdpocX39tWrZsqqXXKJ68GCxizEm5qxdq3ryyarNm6tmZQVX1pEjqp06qSYmqv7wQ2ji88JHH6mC6sCBxXv/5s2qFSqo3nxzaOMKF2Ch5pNXA7lCPxdYo6rrVPUgkAF0Df1XS+Dat3ffqF98AXffHR+3jMYU5rffXCMowPTpUKlScOUlJLieMWXLuuqKWJxqd8cON4CoaVNX/VQcNWrAPfe4KQKWLQttfJEWSEKvCWzye57p25bb9SKyVESmiUjtvAoSkb4islBEFm7btq0Y4R7TsycMGeJasydMCKooY6KeKvz5z7Bihas7b9AgNOXG8ihSVejf3/Unnzo1uGH8Dzzgegk98kjo4vNEfpfueqw6pRvwkt/znuSqXgGqAuV8j28Hviis3GCqXHIcOaJ6zTWqCQnutsuYeDV2rKtWeOKJ8JSfmqpaqpTq/PnhKT8cpk515+Txx0NT3ujRrrxoPwcUUOVS6ORcInI+MFJV/+R7/pDvi2BsPvuXAnaqaoFNE6GanGvvXjch0Y8/wvz5cPbZQRdpTFT5+GO44go3gOiNN/IfLBOMXbtc77GyZd18MMFW54Tbpk1u4q1mzWDOHChVKvgys7LcgiAtWsDnnwdfXrgEOznXAqChiNQXkbLAjcCMXAfw78LfBVhZ3GCLqlIlmDHDjQy76qr4GvVlzJo10KOHSzIvvxyeZA6xNYo0O9stWHH4sIs5FMkcXJXL0KFuKoVZs0JTZqQVmtBV9TBwF/AJLlG/paorRGSUiHTx7XaPiKwQke+Ae3C9XiKmTh3XSPTTT26JqYMHI3l0Y8IjK8s1gpYq5f6+ExPDe7xYGUX67LOuQ8T48e6KOpRuvx1q13Zz4sRkZ4v86mLC/ROKOvTc0tNdHditt6pmZ4e8eGMiJjtb9brrXPvQ559H7rgHDqi2bKl66qmqW7dG7riBWrFCtVw51auvDt//8Zdecnlk+vTwlB8sguy2GDNuugmGDXO3puPHex2NMcX3+OPw7rtu8qhOnSJ33GgeRXrwoJspsnJlePHF8FU/3XKLm3J32DA3ijSWxFVCB3j0UVftcv/9MHOm19EYU3QzZ7ruc6mpbum4SIvWUaSjRrkG20mT4LTTwnec0qXdfDfLl7t5cmJJXC5B99tvcOGFbg3FefPcH6gxsWD1arf25VlnueXiKlTwJo7sbPjjH+E//4ElS9wybl6aNw8uuMA1hr78cviPl50NbdrAnj2wcqXr/RMtStwSdBUruulEK1Vyc74EOYbJmIjYs8c1gpYtC//6l3fJHKJrFOnevS6GOnUityBFQoIbaLVunZtXPVbEZUIHNwLuvfdgyxa3ksvvv3sdkTH5y86GXr3cXeXbb7vk5bVoGUV6331unMlrr7n680jp3Bk6dHBVPfv2Re64wYjbhA5uVZIpU9yta79+0dXAY4y/0aPdBcjTT0PHjl5Hc4zXa5F+8IGrMx882FW5RJIIjB0LP/8Mzz8f2WMXV1zWoef26KNu3uMnnnB/GMZEkxkzoGtX17vi1VfD13ujuLwaRbptmxsNetppbvGKcuUic9zcOnd2x1+3rmhT84ZLiatDz234cHel8eCD7j+PMdFi1SrXFS8lxVVvRFsyB29GkapC377w66+uG6VXyRxcddPOne7uKdqViIQu4q58UlJcX/WlS72OyBjX17trV9f4+e67wc0WGG6RHkU6ZYobHTtmjLtK91Lr1m4xkaefjv4OFiWiyiXH5s2uS1ipUu4WKpx9WY0pSHa2S+Yff+yGsUe6frg4fv8d2rVzdcrLlsGpp4bnOOvXu7lrWrd2c6qEaq6WYKxa5SYCu/de76/US3yVS44zznBVLtu2wbXXwoEDXkdkSqqRI12D39/+FhvJHCIzivTIEdeWAO4qPRqSOUCTJi6uiRPdTI/RqkQldHDf+q+/7gZM9OljPV9M5L37rus10ru3W6AhloR7FOkzz7jpcJ97DurWDX35wRgxwuWL0aO9jqQA+U3yEu6fcEzOVRQ5k9mHanJ8YwKxfLlqxYqq7dqp7t/vdTTFE661SL/7zq0VfN110Tu53j33uIVAVq/2LgaCWeAiXLyoQ/en6vrX/vOf8M47bvCRMeH066+uDWfvXli4EGrmtZBjjMjMdI2VjRu7cR6lSwdX3u+/u3Ejv/zi5lCpVi00cYba1q1u+b8uXbyb58Xq0PMg4uaEaNfODSv+9luvIzLx7MgR18NqwwaYNi22kzmEfhTp8OGuofXll6M3mYPrSDFggFvX9bvvvI7mRCU2oYPrLjZ9OlSt6r5xf/7Z64hMvHrkEdej5bnn3HDyeBCqUaRz5sCTT7rFJa68MnTxhcv997u++cOGeR3JiUp0Qgc4/XTX82XnTjcx0v79Xkdk4s3bb7sh5H37uqQVTyZMcL3Hbr7ZVSUV1Z49rvdIgwZu7vdYcPLJbpDiBx/A1197Hc3xSnxCB0hOhvR01ze9d2/r+VJU2dmwaJF9GeZl6VI35ev557ul0+JNsKNIBwyAjRtdz7NoX5ja3913u+qXaFuqzhK6zzXXuKuojAx47DGvo4kNP/7o5sk56yw3Cjferj6DlXPXV6WKa3j3cvh6OHXsWLxRpNOnuxHcDz3kvvBiScWKrsplzhz47DOvo/GTX/eXcP943W0xL9nZqj17uu6Mb73ldTTRKStLdfJk1Y4d3XkScV3Yrr/ePf/Pf7yOMDocOqR62WWuG15JOCdFXYt0yxbVatVUW7dW/f338McXDgcOqNatq9qmTWS7WVJAt0VL6LkcOKDavr1qhQqqCxZ4HU10OHJEdfZs1bQ014caVM86S/Wxx1Q3bHD7ZGWp1qih2rat27+kGzzYnacXX/Q6kshZtiywBZyzs1Wvukq1fHm36HMsmzzZ/TtPmxa5Y1pCL6KtW1Xr1FE94wzVzEyvo/HOunWqI0eq1q/v/lKSklRvu0117ty8/8O+9prbb/LkyMcaTd57z52H/v29jiTynn7affZJk/Lf58UX3T7jx0curnA5fFj17LNVmzRxjyPBEnoxfPedaqVK7nbqt9+8jiZy8qpSufRS1alTCz8PR464EZCnn666Z09k4o02WVmqtWqpNm8eu1UJwShsFOmaNe4ur1On+LmTmzYtshcyltCLacYMl9C6dYufP768BFKlEqj58937hwwJT6zR7v773eefO9frSLyzaZPqSSe5L/dDh45tP3zYVWdWqaK6caN38YVadra78Ktb11XZhpsl9CA8+aQ7S8OHex1J6BW1SiVQvXq5xsA1a0IXayxYutTN83HbbV5H4r2MDPc3NXLksW2PP+62pad7F1e4fPKJ+2zPPRf+Y1lCD0J2tuqf/+zO1BtveB1N8IKpUgnUTz+5K/1rrglNebHgyBHVDh1cz43t272OJjqkprovuPnzVRcvVi1dWvWGG6J34q1gZGerXnSR6mmnqe7dG95jWUIP0oEDqhdc4Frw58/3OpqiC2WVSqByrsY++yw85Uebl192n/eVV7yOJHr8+qtq7drub61pU9fJYMcOr6MKn7lz3d/A2LHhPU7QCR24HFgNrAGGFLDf9YACKYWVGUsJXVX1l19c1cTpp8dO/d+6daojRqjWqxfaKpVA7N+v2qCBarNmx9ejxqPt21WrVlX9wx/iu62lOL780t0FgurHH3sdTfhdeaVrP9i5M3zHCCqhA6WAtUADoCzwHdA0j/2SgDnA/HhM6KpuLuukJNXk5PDfVhVXVpbqq6+6279wVakE6l//cjFMmBDZ40barbe66oRly7yOJDr9/e+qf/ub11FExpIl7m/+4YfDd4xgE/r5wCd+zx8CHspjv/HAlcDseE3oqqozZ6omJKhee230XI15UaUSiOxs1z3t5JPjt1455zZ78GCvIzHR4sYbXbfNLVvCU35BCT2QaelrAv6r6GUC7fx3EJHWQG1VnSkigwMoM2ZdcYWbFW7QIDdPh/8yWap5Py7seVH2zf38yBGYPdvNq5KUBD16uMmg2rd3c757SQTGj4eWLd3yXRMmeBtPqB065JaQq13bzedtDMCoUW6Gzccfd2vGRlKQ64yAiCQATwNpAezbF+gLUKdOnWAP7ZkBA2DzZnjlleOnz8ydQIvyPJj3Nm3q5qS+9lpITCw8/kg65xyX9F54wU3e1by51xGFzrPPukUZ/vWv2Jop0IRXw4Zu1ta//91d+EVybdRCl6ATkfOBkar6J9/zhwBUdazveRVcHXvObMinAzuBLqqa7xpzXi9BZyJnxw73R96qFXz+ufd3DqGwaROcfTZcfLGbTz8ePpMJnU2b3N/8TTe5C79QCnYJugVAQxGpLyJlgRuBGTkvqupuVa2mqvVUtR6uUbTAZG5KlqpV3W3oF1/Ae+95HU1o3Huvmwf+uecsmZsT1a4Nd9wBU6bAqlWRO26hCV1VDwN3AZ8AK4G3VHWFiIwSkS7hDtDEh379oFkztwjCgQNeRxOcmTNdNcsjj0C9el5HY6LVQw+5KtBItq8UWuUSLlblUvLMmgWXXuoWEhkyxOtoimffPvfFVKECLFkCZct6HZGJZiNGuLvTRYugdevQlBlslYsxIdGpk+sZ9NhjrlE5Fo0ZA+vXw8SJlsxN4QYNglNOgaFDI3M8S+gmosaNc939HnrI60iKbuVKtzp9r15u2TVjClOlirsb/fhjt1xduFlCNxF15pnuquW11+C///U6msCpukauSpVcUjcmUHfeCTVquKv0cNdwW0I3Effww3D66cd6isSC9HQ3gGvsWDj1VK+jMbEkp2F07lz46KPwHssSuom4pCT4y1/cFXp6utfRFO7XX13vnHbtoE8fr6Mxsah3b2jQwF2lh/MixhK68UTPntC2LTz4IOzdW/j+Xho6FLZvd6NdE+x/jCmGsmXh0Uddz6hp08J3HPvzNJ5ISHBD53/+2VVjRKtvvnFDuO++2410Naa4evRwXV4feQQOHw7PMSyhG8+cd567Un/qKVi3zutoTnTkiJuHpkYN15fYmGCUKuW6vf7wgxtBGg6W0I2nxo6F0qVhcBTO0TlxIixeDM88A5Urex2NiQddusCwYXDRReEp3xK68VTNmq7Xy7vvurleosXmza7u/I9/hO7dvY7GxAsRNzPqWWeFp3xL6MZzgwa5OVHuvTd8dYtFNWgQHDwIzz9vk2+Z2GEJ3XiufHlXj758OUya5HU08Nln8OabbjRruK6kjAkHm5zLRAVVN9fLd9/B//7n5r/wwoEDxxbhWLbMfdkYE01sci4T9XKWq9u1C0aO9C6Ov/4V1qxxDaKWzE2ssYRuokaLFm6ZuokTYcWKyB9/zRrX6+bGG+GyyyJ/fGOCZQndRJXRo10XwYEDwz+RkT9VN4lSuXLw9NORO64xoWQJ3USVqlXdEOnPPoP334/ccd9+Gz791M3VXqNG5I5rTChZo6iJOocOQXIy/P67q3opVy68x9uzB5o0cYn8m2/ciD5jopU1ipqYUqaMayBdu9b9Drfhw2HLFjdniyVzE8ssoZuodNllbpj0Y4+5CbzC5dtv4bnn3CLWbduG7zjGRIIldBO1nnrKVbs8/HB4yj9yxCXyatXg8cfDcwxjIskSuolaZ53lertMngwLFoS+/BdfdHXmTz0FJ50U+vKNiTRrFDVRbc8eaNQI6teHefNCN6/K1q2uIbRVK5g1y+ZrMbHDGkVNzKpc2Q32mT8f3ngjdOUOHgy//eYGMVkyN/HCErqJerfcAikp8MADoVmubvZseP11l9SbNAm+PGOihSV0E/VylqvbvNnNtRKMgwfhjjvcdL1Dh4YkPGOiRmmvAzAmEOefD6mp8OSTbgX1+vWLV85TT8HKlTBzJiQmhjbGWHDo0CEyMzM5cOCA16GYQpQvX55atWpRpkyZgN9jjaImZmRmQuPG0Llz8VZO//FHt0hv587wzjuhjy8W/PjjjyQlJVG1alXEGg+ilqqyY8cOsrKyqJ/r6iXoRlERuVxEVovIGhEZksfr/URkmYgsEZG5ItK0WJ/CmALUquUWnXjnHfjyy6K9VxXuucdV30Ri9Gm0OnDggCXzGCAiVK1atch3UoUmdBEpBTwPdAaaAj3ySNhvqGpzVU0GngBsvjoTFvfdB3XrwoABRVuu7r334IMP3MRftWuHL75YYMk8NhTn3ymQK/RzgTWquk5VDwIZQFf/HVR1j9/TioA39Tgm7lWoAOPGwdKl8NJLgb1n7153dd68ufttvLNjxw6Sk5NJTk7m9NNPp2bNmkefHzx4sMD3Lly4kHsC+Ads3759SGKdPXs2V111VUjKipRAEnpNYJPf80zftuOIyJ0ishZ3hZ7nWReRviKyUEQWbtu2rTjxGsP118NFF8GwYfDrr4XvP2oUbNoEL7zgJv4ygUtPdz2CEhLc7/T04MqrWrUqS5YsYcmSJfTr14+BAwcefV62bFkOF3DblZKSwrPPPlvoMebNmxdckDEsZN0WVfV5VT0TeBAYls8+k1Q1RVVTqlevHqpDmxJGBP72N5fMH3204H2XL4dnnoFbb4UOHSITX7xIT4e+fWHDBtcGsWGDex5sUs8tLS2Nfv360a5dOx544AG++eYbzj//fFq1akX79u1ZvXo1cPwV88iRI+nduzcdO3akQYMGxyX6SpUqHd2/Y8eOdOvWjSZNmpCamkpOJ5APP/yQJk2a0KZNG+65555Cr8R37tzJNddcQ4sWLTjvvPNYunQpAP/+97+P3mG0atWKrKwsfv75Zy688EKSk5M555xz+Oqrr0J7wgoQSLfFnwD/Wsdavm35yQBeCCYoYwrTsqVLLhMmuN9N82iGz86G/v2hSpXg+6+XREOHwr59x2/bt89tT00N7bEyMzOZN28epUqVYs+ePXz11VeULl2azz//nIcffph38uiWtGrVKr788kuysrJo3Lgx/fv3P6GL37fffsuKFSs444wz6NChA19//TUpKSncfvvtzJkzh/r169OjR49C4xsxYgStWrVi+vTpfPHFF/Tq1YslS5Ywbtw4nn/+eTp06MDevXspX748kyZN4k9/+hNDhw7lyJEj7Mt9EsMokCv0BUBDEakvImWBG4EZ/juISEO/p1cC/wtdiMbkbdQoSErKf7m6yZNh7lx44gm3EpIpmo0bi7Y9GN27d6eUbzL63bt30717d8455xwGDhzIinwWmL3yyispV64c1apV49RTT2Xr1q0n7HPuuedSq1YtEhISSE5OZv369axatYoGDRoc7Q4YSEKfO3cuPXv2BOCSSy5hx44d7Nmzhw4dOjBo0CCeffZZdu3aRenSpWnbti2vvvoqI0eOZNmyZSQlJRX3tBRZoQldVQ8DdwGfACuBt1R1hYiMEpEuvt3uEpEVIrIEGATcEraIjfGpXh1GjnRLx33wwfGv7djhpgro0AHS0ryILvbVqVO07cGoWLHi0cePPPIIF198McuXL+f999/Pt+teOb+lrEqVKpVn/Xsg+wRjyJAhvPTSS+zfv58OHTqwatUqLrzwQubMmUPNmjVJS0vjtddeC+kxCxJQHbqqfqiqjVT1TFUd49s2XFVn+B7fq6rNVDVZVS9WVQ/WbDcl0R13uPlYBg1yc6fnePBB2LXLNYQm2AQXxTJmzImjaRMT3fZw2r17N8Yice0AAA+VSURBVDVrun4XkydPDnn5jRs3Zt26daxfvx6AN998s9D3XHDBBaT7Gg9mz55NtWrVqFy5MmvXrqV58+Y8+OCDtG3bllWrVrFhwwZOO+00+vTpw2233cbixYtD/hnyY3/qJqblLFe3Zo2b7wXg66/h5ZddVUzz5t7GF8tSU2HSJNfvX8T9njQp9PXnuT3wwAM89NBDtGrVKuRX1AAVKlRg4sSJXH755bRp04akpCSqVKlS4HtGjhzJokWLaNGiBUOGDGHKlCkAjB8/nnPOOYcWLVpQpkwZOnfuzOzZs2nZsiWtWrXizTff5N577w35Z8iPDf03ceHqq+Hf/4bvv4crrnBX599/D74OD8Zn5cqVnH322V6H4bm9e/dSqVIlVJU777yThg0bMnDgQK/DOkFe/142H7qJe08/DQcOQPv2sGyZu1q3ZG7y8+KLL5KcnEyzZs3YvXs3t99+u9chhYTNtmjiQsOGbjqAJ5+Eq66Crl0Lf48puQYOHBiVV+TBsoRu4sYjj7g69TvusFWITMlkCd3EjaSk8PfAMCaaWR26McbECUvoxhgTJyyhG2Mi5uKLL+aTTz45btv48ePp379/vu/p2LEjOV2cr7jiCnbt2nXCPiNHjmTcuHEFHnv69Ol8//33R58PHz6czz//vCjh5ymaptm1hG6MiZgePXqQkZFx3LaMjIyA5lMBN0viSSedVKxj507oo0aN4tJLLy1WWdHKEroxJmK6devGzJkzjy5msX79ejZv3swFF1xA//79SUlJoVmzZowYMSLP99erV4/t27cDMGbMGBo1asQf/vCHo1Psgutj3rZtW1q2bMn111/Pvn37mDdvHjNmzGDw4MEkJyezdu1a0tLSmOZbnHbWrFm0atWK5s2b07t3b373zSNRr149RowYQevWrWnevDmrVq0q8PN5Pc2u9XIxpoQaMACWLAltmcnJBa/Zesopp3Duuefy0Ucf0bVrVzIyMvi///s/RIQxY8ZwyimncOTIETp16sTSpUtp0aJFnuUsWrSIjIwMlixZwuHDh2ndujVt2rQB4LrrrqNPnz4ADBs2jJdffpm7776bLl26cNVVV9GtW7fjyjpw4ABpaWnMmjWLRo0a0atXL1544QUGDBgAQLVq1Vi8eDETJ05k3LhxvFTAUlleT7NrV+jGmIjyr3bxr2556623aN26Na1atWLFihXHVY/k9tVXX3HttdeSmJhI5cqV6dKly9HXli9fzgUXXEDz5s1JT0/Pd/rdHKtXr6Z+/fo0atQIgFtuuYU5c+Ycff26664DoE2bNkcn9MqP19Ps2hW6MSVUQVfS4dS1a1cGDhzI4sWL2bdvH23atOHHH39k3LhxLFiwgJNPPpm0tLQir3ifIy0tjenTp9OyZUsmT57M7Nmzg4o3ZwreYKbfHTJkCFdeeSUffvghHTp04JNPPjk6ze7MmTNJS0tj0KBB9OrVK6hY7QrdGBNRlSpV4uKLL6Z3795Hr8737NlDxYoVqVKlClu3buWjjz4qsIwLL7yQ6dOns3//frKysnj//fePvpaVlUWNGjU4dOjQ0SlvAZKSksjKyjqhrMaNG7N+/XrWrFkDwOuvv85FF11UrM/m9TS7doVujIm4Hj16cO211x6tesmZbrZJkybUrl2bDoUsANu6dWtuuOEGWrZsyamnnkrbtm2PvjZ69GjatWtH9erVadeu3dEkfuONN9KnTx+effbZo42hAOXLl+fVV1+le/fuHD58mLZt29KvX79ifa6ctU5btGhBYmLicdPsfvnllyQkJNCsWTM6d+5MRkYGTz75JGXKlKFSpUohWQjDps81pgSx6XNji02fa4wxJZQldGOMiROW0I0xJk5YQjemhPGq3cwUTXH+nSyhG1OClC9fnh07dlhSj3Kqyo4dOyhfvnyR3mfdFo0pQWrVqkVmZibbtm3zOhRTiPLly1OrVq0ivccSujElSJkyZahfv77XYZgwsSoXY4yJE5bQjTEmTlhCN8aYOGEJ3Rhj4kRACV1ELheR1SKyRkSG5PH6IBH5XkSWisgsEakb+lCNMcYUpNCELiKlgOeBzkBToIeINM2127dAiqq2AKYBT4Q6UGOMMQUL5Ar9XGCNqq5T1YNABtDVfwdV/VJVc9ZPmg8UrfOkMcaYoAWS0GsCm/yeZ/q25edWIM/Z6UWkr4gsFJGFNrDBGGNCK6SNoiJyM5ACPJnX66o6SVVTVDWlevXqoTy0McaUeIGMFP0JqO33vJZv23FE5FJgKHCRqv4emvCMMcYEKpAr9AVAQxGpLyJlgRuBGf47iEgr4B9AF1X9JfRhGmOMKUyhCV1VDwN3AZ8AK4G3VHWFiIwSkS6+3Z4EKgFvi8gSEZmRT3HGGGPCJKA6dFX9UFUbqeqZqjrGt224qs7wPb5UVU9T1WTfT5eCSyye9HSoVw8SEtxvvwW9jTGmxIuZ2RbT06FvX9jn6xy5YYN7DpCa6l1cxhgTLWJm6P/QoceSeY59+9x2Y4wxMZTQN24s2nZjjClpYiah16lTtO3GGFPSxExCHzMGEhOP35aY6LYbY4yJoYSemgqTJkHduiDifk+aZA2ixhiTI2Z6uYBL3pbAjTEmbzFzhW6MMaZgltCNMSZOWEI3xpg4YQndGGPihCV0Y4yJE5bQjTEmTlhCN8aYOGEJ3Rhj4oQldGOMiROW0I0xJk5YQjfGmDhhCd0YY+KEJXRjjIkTltCNMSZOWEI3xpg4YQndGGPihCV0Y4yJE5bQjTEmTlhCN8aYOGEJ3Rhj4oQldGOMiRMBJXQRuVxEVovIGhEZksfrF4rIYhE5LCLdQh+mMcaYwhSa0EWkFPA80BloCvQQkaa5dtsIpAFvhDpAY4wxgSkdwD7nAmtUdR2AiGQAXYHvc3ZQ1fW+17LDEKMxxpgABFLlUhPY5Pc807etyESkr4gsFJGF27ZtK04Rxhhj8hHRRlFVnaSqKaqaUr169Uge2hhj4l4gCf0noLbf81q+bcYYY6JIIAl9AdBQROqLSFngRmBGeMMyxhhTVIUmdFU9DNwFfAKsBN5S1RUiMkpEugCISFsRyQS6A/8QkRXhDNoYY8yJAunlgqp+CHyYa9twv8cLcFUxxhhjPGIjRY0xJk5YQi+G9HSoVw8SEtzv9HSvIzLGmACrXMwx6enQty/s2+eeb9jgngOkpnoXlzHG2BV6EQ0deiyZ59i3z203xhgvWUIvoo0bi7bdGGMixRJ6EdWpU7TtxhgTKZbQi2jMGEhMPH5bYqLbbowxXrKEXkSpqTBpEtStCyLu96RJ1iBqjPGe9XIphtRUS+DGmOhjV+jGGBMnLKEbY0ycsIQew2zEqjHGn9WhxygbsWqMyc2u0GOUjVg1xuRmCT1G2YhVY0xultBjlI1YNcbkZgk9RtmIVWNMbpbQY1Q0jVi13jbGRAfr5RLDomHEqvW2MSZ62BW6CYr1tjEmelhCN0Gx3jbGRA9L6CYo1tvmeNHSnhAtcZjIsoRughJNvW28TmI57QkbNoDqsfaEkhqH8YCqevLTpk0bNfFh6lTVunVVRdzvqVO9iSExUdWlMPeTmBjZWOrWPf74OT9160YuhmiKI5pEw99oqAALNZ+8Ku71yEtJSdGFCxd6cmwTf+rVc1eiudWtC+vXRyaGhASXOnMTgezsyMQQTXFEi9w9scDdRcbqwjQiskhVU/J6zapcTFyIhsbZaGlPiJY4okVJ6ollCd3EhWhIYtHSnhAtcYD37RoQHV/2kWIJ3cSFaEhi0TJ6N1riiJbG2Wj4ss8R9i+4/CrX/X+Ay4HVwBpgSB6vlwPe9L3+X6BeYWVao6gJtXhq+IoH0dI4Gw0N5qGMg2AaRUWkFPADcBmQCSwAeqjq93773AG0UNV+InIjcK2q3lBQudYoakx8i6bG2fR0V2e+caO7Mh8zJvJ3LKFquA+2UfRcYI2qrlPVg0AG0DXXPl2BKb7H04BOIiKBh2iMiTfRVNWRmuqSZna2++1F75ZI1OUHktBrApv8nmf6tuW5j6oeBnYDVXMXJCJ9RWShiCzctm1b8SI2xsSEaGjXiCaR+IKLaKOoqk5S1RRVTalevXokD22MibBoaZyNFpH4ggtk+tyfgNp+z2v5tuW1T6aIlAaqADtCEqExJmZFwxTP0SLnPISzLj+QhL4AaCgi9XGJ+0bgplz7zABuAf4DdAO+0MJaW40xpoQJ9xdcoQldVQ+LyF3AJ0Ap4BVVXSEio3DdZ2YALwOvi8gaYCcu6RtjjImggFYsUtUPgQ9zbRvu9/gA0D20oRljjCkKGylqjDFxwhK6McbECUvoxhgTJzybD11EtgF5DISNKdWA7V4HEUXsfBxj5+J4dj6OF8z5qKuqeQ7k8SyhxwMRWZjfnAolkZ2PY+xcHM/Ox/HCdT6sysUYY+KEJXRjjIkTltCDM8nrAKKMnY9j7Fwcz87H8cJyPqwO3Rhj4oRdoRtjTJywhG6MMXHCEnoxiEhtEflSRL4XkRUicq/XMXlNREqJyLci8oHXsXhNRE4SkWkiskpEVorI+V7H5CURGej7f7JcRP4pIuW9jilSROQVEflFRJb7bTtFRD4Tkf/5fp8cquNZQi+ew8B9qtoUOA+4U0SaehyT1+4FVnodRJT4G/CxqjYBWlKCz4uI1ATuAVJU9RzcjK0laTbWycDlubYNAWapakNglu95SFhCLwZV/VlVF/seZ+H+w+Zelq/EEJFawJXAS17H4jURqQJciJtSGlU9qKq7vI3Kc6WBCr7FbxKBzR7HEzGqOgc3pbg//zWYpwDXhOp4ltCDJCL1gFbAf72NxFPjgQeACK/lHpXqA9uAV31VUC+JSEWvg/KKqv4EjAM2Aj8Du1X1U2+j8txpqvqz7/EW4LRQFWwJPQgiUgl4Bxigqnu8jscLInIV8IuqLvI6lihRGmgNvKCqrYDfCOEtdazx1Q93xX3RnQFUFJGbvY0qevhWdgtZ33FL6MUkImVwyTxdVd/1Oh4PdQC6iMh6IAO4RESmehuSpzKBTFXNuWObhkvwJdWlwI+quk1VDwHvAu09jslrW0WkBoDv9y+hKtgSejGIiODqSFeq6tNex+MlVX1IVWupaj1cY9cXqlpir8BUdQuwSUQa+zZ1Ar73MCSvbQTOE5FE3/+bTpTgRmKfnDWY8f1+L1QFW0Ivng5AT9zV6BLfzxVeB2Wixt1AuogsBZKBxz2OxzO+O5VpwGJgGS7nlJhpAETkn8B/gMYikikitwJ/AS4Tkf/h7mD+ErLj2dB/Y4yJD3aFbowxccISujHGxAlL6MYYEycsoRtjTJywhG6MMXHCEroxxsQJS+jGGBMn/h/HqwiB0785aAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Train fold with 16810 images\n",
      "label\n",
      "covid        6970\n",
      "non covid    9840\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 4756 images\n",
      "label\n",
      "covid        1968\n",
      "non covid    2788\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis1\n",
      "=====\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 448, 448, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 454, 454, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 224, 224, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 224, 224, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 224, 224, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 226, 226, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 112, 112, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 112, 112, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 112, 112, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 112, 112, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 112, 112, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 112, 112, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 112, 112, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 112, 112, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 112, 112, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 112, 112, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 112, 112, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 112, 112, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 112, 112, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 112, 112, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 112, 112, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 56, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 56, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 56, 56, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 56, 56, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 56, 56, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 56, 56, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 56, 56, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 56, 56, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 56, 56, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 56, 56, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 56, 56, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 56, 56, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 56, 56, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 56, 56, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 56, 56, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 56, 56, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 56, 56, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 56, 56, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 28, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 28, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 28, 28, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 28, 28, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 28, 28, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 28, 28, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 28, 28, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 28, 28, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 28, 28, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 28, 28, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 28, 28, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 28, 28, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 28, 28, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 28, 28, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 28, 28, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 28, 28, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 28, 28, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 28, 28, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 28, 28, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 28, 28, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 28, 28, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 28, 28, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 28, 28, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 28, 28, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 28, 28, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 28, 28, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 28, 28, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 28, 28, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 28, 28, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 28, 28, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 28, 28, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 28, 28, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 28, 28, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 28, 28, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 28, 28, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 28, 28, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 28, 28, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 28, 28, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 28, 28, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 28, 28, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 28, 28, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 28, 28, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 28, 28, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 28, 28, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 28, 28, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 28, 28, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 28, 28, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 28, 28, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 28, 28, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 28, 28, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 28, 28, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 28, 28, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 28, 28, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 28, 28, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 28, 28, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 28, 28, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 28, 28, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 28, 28, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 28, 28, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 28, 28, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 28, 28, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 28, 28, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 28, 28, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 28, 28, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 14, 512)  524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 14, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 14, 14, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 14, 14, 2048) 2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 14, 14, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 14, 14, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 14, 14, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 14, 14, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 14, 14, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 14, 14, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 14, 14, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 14, 14, 2048) 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         1049600     dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            2050        batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 45,812,098\n",
      "Trainable params: 45,704,706\n",
      "Non-trainable params: 107,392\n",
      "__________________________________________________________________________________________________\n",
      "Found 16810 validated image filenames belonging to 2 classes.\n",
      "Found 4756 validated image filenames belonging to 2 classes.\n",
      "{'covid': 0, 'non covid': 1}\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9294\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88931, saving model to training/20201029//resnet101v2/fold5/axis1//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold5/axis1//my_checkpoint/assets\n",
      "2101/2101 [==============================] - 2509s 1s/step - loss: 0.1820 - accuracy: 0.9294 - val_loss: 0.5029 - val_accuracy: 0.8893\n",
      "Epoch 2/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9746\n",
      "Epoch 00002: val_accuracy improved from 0.88931 to 0.90930, saving model to training/20201029//resnet101v2/fold5/axis1//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold5/axis1//my_checkpoint/assets\n",
      "2101/2101 [==============================] - 2525s 1s/step - loss: 0.0741 - accuracy: 0.9746 - val_loss: 0.2411 - val_accuracy: 0.9093\n",
      "Epoch 3/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9860\n",
      "Epoch 00003: val_accuracy improved from 0.90930 to 0.93455, saving model to training/20201029//resnet101v2/fold5/axis1//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold5/axis1//my_checkpoint/assets\n",
      "2101/2101 [==============================] - 2509s 1s/step - loss: 0.0426 - accuracy: 0.9860 - val_loss: 0.1598 - val_accuracy: 0.9346\n",
      "Epoch 4/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9915\n",
      "Epoch 00004: val_accuracy did not improve from 0.93455\n",
      "2101/2101 [==============================] - 2476s 1s/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.2195 - val_accuracy: 0.9188\n",
      "Epoch 5/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9932\n",
      "Epoch 00005: val_accuracy did not improve from 0.93455\n",
      "2101/2101 [==============================] - 2478s 1s/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.2230 - val_accuracy: 0.8977\n",
      "Epoch 6/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9939\n",
      "Epoch 00006: val_accuracy did not improve from 0.93455\n",
      "2101/2101 [==============================] - 2501s 1s/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.2437 - val_accuracy: 0.9055\n",
      "Epoch 7/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9960\n",
      "Epoch 00007: val_accuracy did not improve from 0.93455\n",
      "2101/2101 [==============================] - 2479s 1s/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.2595 - val_accuracy: 0.9133\n",
      "Epoch 8/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9963\n",
      "Epoch 00008: val_accuracy did not improve from 0.93455\n",
      "2101/2101 [==============================] - 2479s 1s/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.2357 - val_accuracy: 0.9040\n",
      "Epoch 9/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9961\n",
      "Epoch 00009: val_accuracy did not improve from 0.93455\n",
      "2101/2101 [==============================] - 2478s 1s/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.3080 - val_accuracy: 0.8954\n",
      "Epoch 10/10\n",
      "2053/2101 [============================>.] - ETA: 52s - loss: 0.0105 - accuracy: 0.9971"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, 1))\n",
    "labels = data_train['covid'].unique()\n",
    "\n",
    "labels.sort()\n",
    "labels_length = len(labels)\n",
    "labels_pos_dict = dict(zip(labels, [i for i in range(labels_length)]))\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    \n",
    "    ''' CREATE PATHS FOR SAVE OUTPUT '''\n",
    "    predicted_dir = \"{}/\".format(OUTPUT_PREDICTED_FOLDER)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    predicted_dir = \"{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    ''''''\n",
    "    \n",
    "    ''' CREATE DATAFRAME AND CONFUSION MATRIX - ACCUMULATED '''\n",
    "    # Predicted class for patient and fold\n",
    "    df_axis = pd.DataFrame(columns=['fold', 'patient', 'real', 'predicted', 'count'])\n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix = np.zeros(labels_length*labels_length).reshape(labels_length, labels_length)\n",
    "    ''''''\n",
    "    \n",
    "    for n_fold in [4, 5]:\n",
    "#     for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_train = pd.read_csv(\"{}/train/train{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        train_df, validation_df = get_data_set(n_fold, axis, data_train, data_validation)\n",
    "        data_validation_dict = dict(zip(data_validation.nome, data_validation.covid))\n",
    "        \n",
    "        print('\\n'+axis+'\\n=====')\n",
    "        model, SELECTED_MODEL = get_model_resnet101v2()\n",
    "        history = train_model(model, train_df, validation_df, EPOCHS, n_fold, axis)\n",
    "        \n",
    "        #Plot Results\n",
    "        plot_results(history, axis, n_fold, SELECTED_MODEL)\n",
    "        # Load legend\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        \n",
    "        \n",
    "#         '''  GET DATA  '''\n",
    "#         # Test with other patients\n",
    "#         df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)\n",
    "#         idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "#         df = df[idx]\n",
    "#         df.reset_index(drop=True, inplace=True)\n",
    "#         df['fold'] = n_fold\n",
    "#         df['real'] = ''\n",
    "#         last_patient = ''\n",
    "        \n",
    "#         for index, row in df.iterrows():\n",
    "#             if row['patient'] != last_patient:\n",
    "#                 df.loc[index, 'real'] = data_validation_dict[row['patient']]\n",
    "#                 real_label_pos = labels_pos_dict[data_validation_dict[row['patient']]]\n",
    "#                 pred_label_pos = labels_pos_dict[row['predicted']]\n",
    "#                 confusion_matrix[real_label_pos][pred_label_pos] += 1\n",
    "#             last_patient = row['patient']        \n",
    "#         df_axis = df_axis.append(df)\n",
    "#         '''''' '''''' ''''''\n",
    "        \n",
    "#     predicted_dir = \"{}/{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis, SELECTED_MODEL)\n",
    "#     if not os.path.exists(predicted_dir): \n",
    "#         os.mkdir(predicted_dir)\n",
    "#     df_axis.to_csv(predicted_dir+'predicted.csv', index=False)\n",
    "#     print(labels_pos_dict)\n",
    "#     print(confusion_matrix)\n",
    "    \n",
    "#     '''\n",
    "#     PRINT METRICS AND CONFUSION MATRIX\n",
    "#     '''\n",
    "#     pm.plot_labels_metrics(cm=confusion_matrix, normalize=False, labels=labels, show_zero=False,\n",
    "#                 title='Metrics', clear_diagonal=False, figsize=(15, 105), output_file=\"metrics.png\"\n",
    "#                           )\n",
    "#     pm.plot_confusion_matrix(cm=confusion_matrix, normalize=False, labels=labels, show_zero=False,\n",
    "#                 title=\"Confusion Matrix\", clear_diagonal=False, output_file=\"matrix.png\", figsize=(10, 7)\n",
    "#                             )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models!\n",
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HMV + HCPA\n",
    "'''\n",
    "data_train = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, 1))\n",
    "labels = data_train['covid'].unique()\n",
    "\n",
    "labels.sort()\n",
    "labels_length = len(labels)\n",
    "labels_pos_dict = dict(zip(labels, [i for i in range(labels_length)]))\n",
    "\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=======================================================================================')\n",
    "    \n",
    "    predicted_dir = \"{}/\".format(OUTPUT_PREDICTED_FOLDER)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    predicted_dir = \"{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    \n",
    "    \n",
    "    # Predicted class for patient and fold\n",
    "    df_axis = pd.DataFrame(columns=['fold', 'patient', 'real', 'predicted', 'count'])\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix = np.zeros(labels_length*labels_length).reshape(labels_length, labels_length)\n",
    "\n",
    "#     for n_fold in [1, 2, 3, 4, 5]: \n",
    "    for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        \n",
    "        data_validation_dict = dict(zip(data_validation.nome, data_validation.covid))\n",
    "        \n",
    "        model, SELECTED_MODEL = get_model_resnet101v2()\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        \n",
    "        model = tf.keras.models.load_model(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        \n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)\n",
    "        idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "        df = df[idx]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df['fold'] = n_fold\n",
    "        df['real'] = ''\n",
    "        last_patient = ''\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            if row['patient'] != last_patient:\n",
    "                df.loc[index, 'real'] = data_validation_dict[row['patient']]\n",
    "                real_label_pos = labels_pos_dict[data_validation_dict[row['patient']]]\n",
    "                pred_label_pos = labels_pos_dict[row['predicted']]\n",
    "                confusion_matrix[real_label_pos][pred_label_pos] += 1\n",
    "            last_patient = row['patient']        \n",
    "        df_axis = df_axis.append(df)\n",
    "        del model\n",
    "        \n",
    "    predicted_dir = \"{}/{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis, SELECTED_MODEL)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    df_axis.to_csv(predicted_dir+'predicted.csv', index=False)\n",
    "    print(labels_pos_dict)\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    '''\n",
    "    PRINT METRICS AND CONFUSION MATRIX\n",
    "    '''\n",
    "    pm.plot_labels_metrics(\n",
    "                cm=confusion_matrix,\n",
    "                normalize=False,\n",
    "                labels=labels,\n",
    "                show_zero=False,\n",
    "                title='Metrics - ' + axis,\n",
    "                clear_diagonal=False,\n",
    "                figsize=(15, 105),\n",
    "                output_file=\"metrics.png\"\n",
    "            )\n",
    "    pm.plot_confusion_matrix(\n",
    "                cm=confusion_matrix,\n",
    "                normalize=False,\n",
    "                labels=labels,\n",
    "                show_zero=False,\n",
    "                title=\"Confusion Matrix - \" + axis,\n",
    "                clear_diagonal=False,\n",
    "                output_file=\"matrix.png\",\n",
    "                figsize=(10, 7)\n",
    "#                 verbose=args.verbose,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=====')\n",
    "    for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))        \n",
    "        #model, SELECTED_MODEL = get_model_resnet50()\n",
    "        SELECTED_MODEL = 'vgg16'\n",
    "        df = pd.read_csv(\"{}/{}/fold{}/{}/history.csv\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        print(max(df['val_accuracy']))\n",
    "        print((df['val_accuracy'].mean()))\n",
    "#         print(df['val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
