{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_TEST = \"exame-pulmao\"\n",
    "TRAIN_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA-tf12-all/\" + FOLDER_TEST\n",
    "VALIDATION_IMG_SRC_FOLDER = \"/home/guilherme/Documents/noa/cidia19/data/output-2d/HMV-HCPA-tf12-all/\" + FOLDER_TEST\n",
    "\n",
    "# SUB_FILE = ['axis2', 'axis4']\n",
    "SUB_FILE = ['axis2']\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_HEIGHT = 448\n",
    "IMG_WIDTH = 448\n",
    "IMG_CHANNELS = 3\n",
    "SELECTED_MODEL = ''\n",
    "NUM_CLASSES = 2\n",
    "DATA_FOLDER = '20201029/'\n",
    "LOG_FOLDER = 'logs/' + DATA_FOLDER\n",
    "TRAINING_FOLDER = 'training/' + DATA_FOLDER\n",
    "MODEL_FOLDER = 'models/' + DATA_FOLDER\n",
    "IMAGE_FOLDER = 'images/' + DATA_FOLDER\n",
    "\n",
    "STRUCTURE_DATASET_FOLDER = \"csv/input/\"+DATA_FOLDER\n",
    "OUTPUT_PREDICTED_FOLDER = \"csv/output/\" + DATA_FOLDER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import utilities.plot_metrics as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(folder, search_filter=''):\n",
    "    '''\n",
    "    Get all files (full path) contained in a PATH folder by specified search filter \n",
    "    '''\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_data_set(fold_number, cur_subfile, data_train, data_test):\n",
    "    ''' Creates and returns a dataframe with all the full paths (for slice) for train and test images. \n",
    "    Save it as log. \n",
    "    '''\n",
    "    dfs = []\n",
    "    train_images = {\"id\": [], \"label\": []}\n",
    "    validation_images = {\"id\": [], \"label\": []}\n",
    "    \n",
    "    \n",
    "    TRAIN_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        TRAIN_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "\n",
    "    VALIDATION_IMG_FOLDERS_SLICE = {}\n",
    "    for _, row in data_test.iterrows():\n",
    "        VALIDATION_IMG_FOLDERS_SLICE[row['nome']] = row['covid']\n",
    "    \n",
    "    df_config = [\n",
    "        (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS_SLICE, train_images),\n",
    "        (VALIDATION_IMG_SRC_FOLDER, VALIDATION_IMG_FOLDERS_SLICE, validation_images)\n",
    "    ]\n",
    "    for (base, folder, dic) in df_config:\n",
    "        for img_folder, img_label in folder.items():\n",
    "            search_folder = \"{}/{}\".format(base, img_folder)\n",
    "            imgs_filename = sorted(get_file_path(search_folder, search_filter = cur_subfile))\n",
    "            dic[\"id\"].extend(imgs_filename)\n",
    "            dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "        dfs.append(pd.DataFrame(data=dic))\n",
    "#     print(dfs)\n",
    "    train_df, validation_df = dfs[0], dfs[1]\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"logs/\"): \n",
    "        os.mkdir(\"logs/\")\n",
    "    if not os.path.exists(LOG_FOLDER): \n",
    "        os.mkdir(LOG_FOLDER)\n",
    "        \n",
    "    train_df.to_csv(\"{}/train{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "    validation_df.to_csv(\"{}/test{}.csv\".format(LOG_FOLDER, fold_number), index=False)\n",
    "\n",
    "    print(\"Train fold with {} images\".format(len(train_df)))\n",
    "    print(train_df.groupby(\"label\").label.count())\n",
    "    print()\n",
    "    print(\"Validation fold with {} images\".format(len(validation_df)))\n",
    "    print(validation_df.groupby(\"label\").label.count())\n",
    "    print(\"-\" * 30)\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel=img.shape\n",
    "    if side_type==\"horizontal\":\n",
    "        return np.ones((height,side_size,  channel), dtype=np.float32)*255\n",
    "        \n",
    "    return np.ones((side_size, width,  channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show=\"all\"):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(train_images[\"id\"])\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(train_images[\"label\"])\n",
    "    for path, target in zip(train_images[\"id\"], train_images[\"label\"]):\n",
    "        if target!=show and show!=\"all\":\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        #Image loading from disk as JpegImageFile file format\n",
    "        img=load_img(path, target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "        #Converting JpegImageFile to numpy array\n",
    "        img=img_to_array(img)\n",
    "        \n",
    "        hside=get_side(img, side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if counter%10==0:\n",
    "            himage=np.hstack((images))\n",
    "            vside=get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images=list()\n",
    "\n",
    "    gallery=np.vstack((vertical_images)) \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title = {\"all\":\"All Classifications's\",\n",
    "             \"healthy\":\"Healthy\",\n",
    "             \"covid\":\"Covid-19\"}\n",
    "    plt.title(\"100 Samples of {} Patients of the training set\".format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_gallery(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True, batch_size=32, class_mode=\"binary\"):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    )\n",
    "    \n",
    "    data_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        subset=subset,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        class_mode=class_mode,\n",
    "        # color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    base_model = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_resnet101v2():\n",
    "    with tf.device('/GPU:0'):\n",
    "        conv_base = get_base_model()\n",
    "        conv_base.trainable = True\n",
    "        \n",
    "#         set_trainable = False\n",
    "#         for layer in conv_base.layers:\n",
    "#             if layer.name == 'block1_conv1':\n",
    "#                 set_trainable = True\n",
    "#             if set_trainable:\n",
    "#                 layer.trainable = True\n",
    "#             else:\n",
    "#                 layer.trainable = False\n",
    "\n",
    "        x = conv_base.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        '''Added'''\n",
    "        x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        preds = tf.keras.layers.Dense(units=NUM_CLASSES, activation = 'softmax')(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=conv_base.input, outputs=preds)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5),\n",
    "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return (model, 'resnet101v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df, validation_df, epochs, fold, axis):\n",
    "    batch_size = 8\n",
    "    train_generator = get_data_generator(train_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "    validation_generator = get_data_generator(validation_df, \"id\", \"label\", batch_size=batch_size, class_mode=\"categorical\")\n",
    "\n",
    "    print(train_generator.class_indices)\n",
    "    print(validation_generator.class_indices)\n",
    "    \n",
    "    step_size_train = train_generator.n // train_generator.batch_size\n",
    "    step_size_validation = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "    if step_size_train == 0:\n",
    "        step_size_train = train_generator.n // 2\n",
    "        step_size_validation = validation_generator.n // 2\n",
    "        \n",
    "        \n",
    "    # callbacks, save each time\n",
    "    # training/20200827/vgg16/fold4/axis2\n",
    "    checkpoint_path = \"training/\"\n",
    "    if not os.path.exists(\"training/\"): \n",
    "        os.mkdir(\"training/\")\n",
    "    checkpoint_path = \"{}/\".format(TRAINING_FOLDER)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    checkpoint_path = \"{}/{}/fold{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "    \n",
    "    checkpoint_path = \"{}/{}/fold{}/{}/\".format(TRAINING_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(checkpoint_path): \n",
    "        os.mkdir(checkpoint_path)\n",
    "        \n",
    "    # Save dict results of history and legend from current model\n",
    "    # models/20200827/vgg16/fold4/axis2/{history|legend}\n",
    "    if not os.path.exists(\"models/\"): \n",
    "        os.mkdir(\"models/\")\n",
    "    \n",
    "    model_dir = \"{}/\".format(MODEL_FOLDER)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}\".format(MODEL_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    model_dir = \"{}/{}/fold{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_dir = \"{}/{}/fold{}/{}/\".format(MODEL_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(model_dir): \n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "#     checkpoint_path = checkpoint_path + \"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_path = checkpoint_path +\"/my_checkpoint\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 25 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True\n",
    "    )\n",
    "        \n",
    "    history = model.fit(train_generator, # X_Train\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=step_size_validation,\n",
    "        callbacks=cp_callback\n",
    "                       )\n",
    "    \n",
    "    # Save last values\n",
    "#     model.save_weights(checkpoint_dir+\"/my_checkpoint\")\n",
    "    # model.save(checkpoint_dir+\"/my_checkpoint\")\n",
    "    \n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = model_dir + 'history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    \n",
    "    # Save classes\n",
    "    print(train_generator.class_indices)\n",
    "    np.save(model_dir + 'legend', train_generator.class_indices)\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(history, sub_folder, fold, sel_model):\n",
    "    acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    \n",
    "    image_dir = \"images/\"\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/\".format(IMAGE_FOLDER)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    image_dir = \"{}/{}/fold{}/{}/\".format(IMAGE_FOLDER, SELECTED_MODEL, fold, axis)\n",
    "    if not os.path.exists(image_dir): \n",
    "        os.mkdir(image_dir)\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(image_dir + 'accuracy', pad_inches=0.1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(image_dir + 'loss', orientation='portrait', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate model for data folders (patients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_by_patient(model, patients, legend_file, axis):\n",
    "    results = []\n",
    "    for p in patients:\n",
    "        # for axis in SUB_FILE:\n",
    "        curr_dir = \"{}/{}/{}\".format(VALIDATION_IMG_SRC_FOLDER, p, axis)\n",
    "        imgs_filename = sorted(os.listdir(curr_dir))\n",
    "        test_filenames = imgs_filename[:]\n",
    "        test_df = pd.DataFrame({\n",
    "                'filename': test_filenames\n",
    "            })\n",
    "        nb_samples = test_df.shape[0]\n",
    "\n",
    "        test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_gen.flow_from_dataframe(\n",
    "                test_df, \n",
    "                curr_dir, \n",
    "                x_col='filename',\n",
    "                y_col=None,\n",
    "                class_mode=None,\n",
    "                target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                batch_size=16,\n",
    "                shuffle=False\n",
    "        )\n",
    "\n",
    "        predict = model.predict(test_generator, steps=np.ceil(nb_samples/16))\n",
    "\n",
    "        test_df['predicted'] = [np.where(pr == np.max(pr))[0][0] for pr in predict]\n",
    "        test_df['patient'] = p\n",
    "        test_df['axis'] = axis\n",
    "        results.append(test_df)\n",
    "\n",
    "    print('Axis: ', test_df['axis'][0])\n",
    "    df_result = pd.DataFrame(columns=['predicted', 'patient','count'])\n",
    "    for i,test_df in enumerate(results):\n",
    "        cur_patient = test_df['patient'][0]\n",
    "        if os.path.isfile(legend_file+'.npy'):\n",
    "            class_indices = np.load(legend_file+'.npy', allow_pickle=True).item()\n",
    "            class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "            test_df['predicted'] = test_df['predicted'].replace(class_indices)\n",
    "        test_df['count'] = 1\n",
    "        test_df = test_df.groupby('predicted', as_index = False)['count'].count()\n",
    "        test_df['patient'] = cur_patient\n",
    "        df_result = df_result.append(test_df)\n",
    "    return df_result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model for 'axis1...n' and folds [ 1...N ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Train fold with 17302 images\n",
      "label\n",
      "covid         7134\n",
      "non covid    10168\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 4264 images\n",
      "label\n",
      "covid        1804\n",
      "non covid    2460\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis2\n",
      "=====\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 448, 448, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 454, 454, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 224, 224, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 224, 224, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 224, 224, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 226, 226, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 112, 112, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 112, 112, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 112, 112, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 112, 112, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 112, 112, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 112, 112, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 112, 112, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 112, 112, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 112, 112, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 112, 112, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 112, 112, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 112, 112, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 112, 112, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 112, 112, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 112, 112, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 56, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 56, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 56, 56, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 56, 56, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 56, 56, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 56, 56, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 56, 56, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 56, 56, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 56, 56, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 56, 56, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 56, 56, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 56, 56, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 56, 56, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 56, 56, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 56, 56, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 56, 56, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 56, 56, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 56, 56, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 28, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 28, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 28, 28, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 28, 28, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 28, 28, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 28, 28, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 28, 28, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 28, 28, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 28, 28, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 28, 28, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 28, 28, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 28, 28, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 28, 28, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 28, 28, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 28, 28, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 28, 28, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 28, 28, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 28, 28, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 28, 28, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 28, 28, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 28, 28, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 28, 28, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 28, 28, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 28, 28, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 28, 28, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 28, 28, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 28, 28, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 28, 28, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 28, 28, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 28, 28, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 28, 28, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 28, 28, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 28, 28, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 28, 28, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 28, 28, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 28, 28, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 28, 28, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 28, 28, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 28, 28, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 28, 28, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 28, 28, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 28, 28, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 28, 28, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 28, 28, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 28, 28, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 28, 28, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 28, 28, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 28, 28, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 28, 28, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 28, 28, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 28, 28, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 28, 28, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 28, 28, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 28, 28, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 28, 28, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 28, 28, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 28, 28, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 28, 28, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 28, 28, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 28, 28, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 28, 28, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 28, 28, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 28, 28, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 28, 28, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 14, 512)  524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 14, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 14, 14, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 14, 14, 2048) 2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 14, 14, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 14, 14, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 14, 14, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 14, 14, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 14, 14, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 14, 14, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 14, 14, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 14, 14, 2048) 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024)         4096        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 45,812,098\n",
      "Trainable params: 45,704,706\n",
      "Non-trainable params: 107,392\n",
      "__________________________________________________________________________________________________\n",
      "Found 17302 validated image filenames belonging to 2 classes.\n",
      "Found 4264 validated image filenames belonging to 2 classes.\n",
      "{'covid': 0, 'non covid': 1}\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.9377\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80957, saving model to training/20201029//resnet101v2/fold4/axis2//my_checkpoint\n",
      "WARNING:tensorflow:From /home/guilherme/Documents/noa/cidia19/jupyter/env-cnn/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold4/axis2//my_checkpoint/assets\n",
      "2162/2162 [==============================] - 2553s 1s/step - loss: 0.1577 - accuracy: 0.9377 - val_loss: 0.7703 - val_accuracy: 0.8096\n",
      "Epoch 2/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9796\n",
      "Epoch 00002: val_accuracy improved from 0.80957 to 0.84545, saving model to training/20201029//resnet101v2/fold4/axis2//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold4/axis2//my_checkpoint/assets\n",
      "2162/2162 [==============================] - 2550s 1s/step - loss: 0.0602 - accuracy: 0.9796 - val_loss: 0.5950 - val_accuracy: 0.8455\n",
      "Epoch 3/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9865\n",
      "Epoch 00003: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2518s 1s/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.7544 - val_accuracy: 0.7838\n",
      "Epoch 4/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9917\n",
      "Epoch 00004: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.6457 - val_accuracy: 0.8304\n",
      "Epoch 5/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9943\n",
      "Epoch 00005: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.7903 - val_accuracy: 0.8161\n",
      "Epoch 6/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9920\n",
      "Epoch 00006: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2520s 1s/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.3833 - val_accuracy: 0.8229\n",
      "Epoch 7/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9947\n",
      "Epoch 00007: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.6563 - val_accuracy: 0.7976\n",
      "Epoch 8/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9967\n",
      "Epoch 00008: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.8681 - val_accuracy: 0.8286\n",
      "Epoch 9/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9950\n",
      "Epoch 00009: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.7351 - val_accuracy: 0.8133\n",
      "Epoch 10/10\n",
      "2162/2162 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9968\n",
      "Epoch 00010: val_accuracy did not improve from 0.84545\n",
      "2162/2162 [==============================] - 2519s 1s/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.7010 - val_accuracy: 0.8053\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU1f3/8deHuq4UaTaQYqJiQdraQAxGMYgGLKAiKqhfsBt7MDaCookSo8TyExsGMNgSxV5QYovKooCAoKgIa0GKIIrU/fz+OHeX2WUXdpfZvcPd9/Px2MfO3PqZMzOfOfecc+81d0dERJKrRtwBiIhI5VKiFxFJOCV6EZGEU6IXEUk4JXoRkYRTohcRSTgl+mrIzF40s4HpXjZOZjbfzI6shO1ONrP/ix4PMLNXyrJsBfbT0sx+MrOaFY1VpDRK9NuIKAkU/OWb2S8pzweUZ1vufrS7P5LuZTORmQ01szdLmN7UzNaa2X5l3Za7j3f3o9IUV5EfJndf4O713H1DOrYvkkqJfhsRJYF67l4PWAD8PmXa+ILlzKxWfFFmpHFAFzNrU2z6KcDH7j4zhpiqDX0eM4MS/TbOzLqbWZ6Z/dHMvgMeNrNGZvacmS02sx+ixy1S1kltjhhkZm+b2cho2S/N7OgKLtvGzN40s5Vm9pqZ3W1m40qJuywx3mhm70Tbe8XMmqbMP93MvjKzpWZ2TWnl4+55wOvA6cVmnQH8c0txFIt5kJm9nfK8h5nNMbMVZnYXYCnzfmVmr0fxLTGz8Wa2QzRvLNASeDY6IrvKzFqbmRckRjPb1cwmmtkyM5tnZoNTtj3MzB43s39GZTPLzHJKKwMzu9PMFprZj2Y21cy6pcyraWZ/MrPPo21NNbPdonn7mtmrUQyLzOxP0fQxZnZTyja6m1leyvP50edxBvCzmdWKjqwK9jHbzI4vFuNgM/skZX4nM7vSzJ4qttwoM7uztNcqJVOiT4adgcZAK2AI4X19OHreEvgFuGsz6x8EzAWaArcCD5qZVWDZR4EPgCbAMDZNrqnKEuOpwJnAjkAd4AoAM9sHuDfa/q7R/kpMzpFHUmMxs72ADlG85S2rgm00Bf4NXEsoi8+BrqmLALdE8e0N7EYoE9z9dIoeld1awi4mAHnR+n2Bm83stynze0fL7ABM3ELMU6LX2zh6zU+YWVY07zKgP9ALaACcBawys/rAa8BLUQy/BiZtrkyK6Q8cA+zg7usJ5dMNaAj8GRhnZrsAmFk/QtmcEcXQG1hKOBrrmfIDWYtwJPbPcsQhAO6uv23sD5gPHBk97g6sBbI2s3wH4IeU55OB/4seDwLmpczLBhzYuTzLEpLkeiA7Zf44YFwZX1NJMV6b8vx84KXo8fXAhJR520dlcGQp284GfgS6RM9HAM9UsKzejh6fAbyXspwREvP/lbLd44CPSnoPo+eto7KsRfhR2ADUT5l/CzAmejwMeC1l3j7AL+X4/PwAtI8ezwX6lLBM/9R4i80bA9yU8rw7kFfstZ21hRimFewXeBn4QynLvQgMjh4fC8yuiu9Y0v5Uo0+Gxe6+uuCJmWWb2X1R08aPwJvADlb6iI7vCh64+6roYb1yLrsrsCxlGsDC0gIuY4zfpTxelRLTrqnbdvefCTXAEkUxPQGcER19DCCqFVagrAoUj8FTn5vZTmY2wcy+jrY7jlDzL4uCslyZMu0roHnK8+Jlk2WltIeb2RVRs8gKM1tOqFUXxLIbobZdXGnTy6rIe29mZ5jZNDNbHsWwXxligHA0dlr0+DRg7FbEVG0p0SdD8UuQXg7sBRzk7g2Aw6LppTXHpMO3QGMzy06Ztttmlt+aGL9N3Xa0zyZbWOcR4CSgB1AfeHYr4ygeg1H09d5MeF/aRds9rdg2N3fZ2G8IZVk/ZVpL4OstxLSJqD3+KsJrb+TuOwArUmJZCPyqhFUXAruXstmfCUdJBXYuYZnC12dmrYD7gQuBJlEMM8sQA8DTwP4WRkcdC4wvZTnZDCX6ZKpPaGtebmaNgRsqe4fu/hWQCwwzszpmdgjw+0qK8UngWDM71MzqAMPZ8mf5LWA5MJrQ7LN2K+N4HtjXzE6IatIXUzTh1Qd+AlaYWXPgymLrL6KUROruC4F3gVvMLMvM9gfOJhwVlFd9QpPaYqCWmV1PaAcv8ABwo5ntYcH+ZtYEeA7YxcwuMbO6ZlbfzA6K1pkG9DKzxma2M3DJFmLYnpD4FwOY2ZmEGn1qDFeYWecohl9HPw5ER6pPEvX/uPuCCpRBtadEn0x3ANsBS4D3CB1qVWEAcAihGeUm4DFgTSnLVjhGd58FXED48n9LaHPO28I6TmiuaUXRzrwKxeHuS4B+wF8Ir3cP4J2URf4MdCLUnp8ndNymugW4NmrKuKKEXfQntNt/A/wHuMHdXytLbMW8THhNnxKaf1ZTtFnlduBx4BVCP8aDwHZRs1EPwo/1d8BnwOHROmOB6YS2+FcI73Op3H028Dfgf4QfuHaklJW7P0HoN3kUWEmoxTdO2cQj0Tpqtqkgizo5RNLOzB4D5rh7pR9RSHKZWUtgDmGAwI9xx7MtUo1e0sbMDrAwfryGmfUE+hBqZyIVYmY1CENAJyjJV5zOWpN02pnQRNGE0JRynrt/FG9Isq0ys+0JTT1fAT1jDmebpqYbEZGEU9ONiEjCZVzTTdOmTb1169ZxhyEisk2ZOnXqEndvVtK8jEv0rVu3Jjc3N+4wRES2KWb2VWnz1HQjIpJwSvQiIgm3xURvZg+Z2fdmVuINGqJTlkdZuGb2DDPrlDJvoJl9Fv1l/O3oRESSqCw1+jFsfgzr0YTTv/cgXAv9XoCU64YcBBwI3GBmjbYmWBERKb8tJnp3fxNYtplF+gD/9OA9wiVedwF+B7zq7svc/QfgVXTSg4hIlUtHG31zil4kKS+aVtr0TZjZEDPLNbPcxYsXpyEkEclk48dD69ZQo0b4P76aX3y4sssjI4ZXuvtowuVjycnJ0am6Igk2fjwMGQKrolvUfPVVeA4wYEB8ccWlKsojHTX6ryl6w4UW0bTSpotIjOKuTV9zzcakVmDVqjC9qsVdFlA15ZGORD+R6BZtZnYwsMLdvyVcB/soM2sUdcIeFU0TqVKZ8GXOFAW1x6++AveNtceqLJMFpdw6pLTplSUTygKqqDy2dFNZ4F+EmzusI7Sznw2cC5wbzTfgbsI9Hz8GclLWPQuYF/2dWZab2Hbu3NlF0mXcOPfsbPfwVQ5/2dlhenXUqlXRsij4a9WqesWQxDiAXC8tj5c2I64/JfrkGDcufFjNwv84kmumfJndM6M8zEouD7OqiyFTfnwzoSzc01ceSvRS5fRlLipTyiNTfvgy4UcvU8rCPT3loUQvVS5TvkSKo6hM+cHJBEkri80lel3rRipFpnS4jRgB2dlFp2Vnh+lVKVPKY8AAGD0aWrUCs/B/9OjqOayxOpVFxt1hKicnx3WZ4m1f69ZhFENxrVrB/PlVG8v48WGo2oIF0LJlSPJV/WXOpPKQZDKzqe6eU9I81egTKBOGE2ZKTRpCUp8/H/Lzw/84amyZVB5S/SjRJ0ymjA2uTofFZaHykDip6SZh1EQgUj2p6aYayZROPxHJHEr0CdOyZfmmi0jyKdEnjDr9RKQ4Jfo0yoTRLur0E5HiMuJ69EmQSdfYHjBAiV1ENlKNPk0y6RrbIiKplOjTRKNdRCRTKdGniUa7iEimUqJPE412EZFMpUSfJhrtIiKZSqNu0kijXUQkE6lGLyKScEr0IiIJp0QvIpJwSvQiIgmnRC8iknBK9CIiCadELyKScEr0IiIJp0QvIpJwSvQiIgmnRC8iknBK9CIiCadELyKScEr0IiIJp0QvIpJwSvQiIgmnRC8iknBK9CIiCadELyKScEr0IiIJV6ZEb2Y9zWyumc0zs6ElzG9lZpPMbIaZTTazFinzNpjZtOhvYjqDFxGRLau1pQXMrCZwN9ADyAOmmNlEd5+dsthI4J/u/oiZ/Ra4BTg9mveLu3dIc9wiIlJGZanRHwjMc/cv3H0tMAHoU2yZfYDXo8dvlDBfRERiUpZE3xxYmPI8L5qWajpwQvT4eKC+mTWJnmeZWa6ZvWdmx5W0AzMbEi2Tu3jx4nKELyIiW5KuztgrgN+Y2UfAb4CvgQ3RvFbungOcCtxhZr8qvrK7j3b3HHfPadasWZpCEhERKEMbPSFp75byvEU0rZC7f0NUozezesCJ7r48mvd19P8LM5sMdAQ+3+rIRUSkTMpSo58C7GFmbcysDnAKUGT0jJk1NbOCbV0NPBRNb2RmdQuWAboCqZ24IiJSybaY6N19PXAh8DLwCfC4u88ys+Fm1jtarDsw18w+BXYCRkTT9wZyzWw6oZP2L8VG64iISCUzd487hiJycnI8Nzc37jBERLYpZjY16g/dhM6MFRFJOCV6EZGES0yiHz8eWreGGjXC//Hj445IRCQzlGV4ZcYbPx6GDIFVq8Lzr74KzwEGDIgvLhGRTJCIGv0112xM8gVWrQrTRUSqu0Qk+gULyjddRKQ6SUSib9myfNNFRKqTRCT6ESMgO7votOzsMF1EpLpLRKIfMABGj4ZWrcAs/B89Wh2xIiKQkFE3EJK6EruIyKYSUaMXEZHSKdGLiCScEr2ISMIp0YuIJJwSvYhIwinRi4gknBK9iEjCKdGLiCScEr2ISMIp0YuIJJwSvYhIwinRi4gknBK9iEjCKdGLiCScEr2ISMIp0YuIJJwSvYhIwinRi4gknBK9iEjCKdGLiCScEr2ISMIp0YuIJJwSvYhIwtWKOwARyRzr1q0jLy+P1atXxx2KlCIrK4sWLVpQu3btMq+jRC8ihfLy8qhfvz6tW7fGzOIOR4pxd5YuXUpeXh5t2rQp83pquhGRQqtXr6ZJkyZK8hnKzGjSpEm5j7iU6EWkCCX5zFaR96dMid7MeprZXDObZ2ZDS5jfyswmmdkMM5tsZi1S5g00s8+iv4HljlBEqo2lS5fSoUMHOnTowM4770zz5s0Ln69du3az6+bm5nLxxRdvcR9dunRJV7jbDnff7B9QE/gc2B2oA0wH9im2zBPAwOjxb4Gx0ePGwBfR/0bR40ab21/nzp1dROIxe/bsci0/bpx7q1buZuH/uHHpi+WGG27w2267rci0devWpW8H27CS3icg10vJq2Wp0R8IzHP3L9x9LTAB6FNsmX2A16PHb6TM/x3wqrsvc/cfgFeBnuX6JRKRjDR+PAwZAl99Be7h/5AhYXo6DRo0iHPPPZeDDjqIq666ig8++IBDDjmEjh070qVLF+bOnQvA5MmTOfbYYwEYNmwYZ511Ft27d2f33Xdn1KhRhdurV69e4fLdu3enb9++tG3blgEDBhRUXHnhhRdo27YtnTt35uKLLy7cbqr58+fTrVs3OnXqRKdOnXj33XcL5/31r3+lXbt2tG/fnqFDQyPIvHnzOPLII2nfvj2dOnXi888/T29BbUZZRt00BxamPM8DDiq2zHTgBOBO4Higvpk1KWXd5sV3YGZDgCEALVu2LGvsIhKja66BVauKTlu1KkwfMCC9+8rLy+Pdd9+lZs2a/Pjjj7z11lvUqlWL1157jT/96U889dRTm6wzZ84c3njjDVauXMlee+3Feeedt8mQxI8++ohZs2ax66670rVrV9555x1ycnI455xzePPNN2nTpg39+/cvMaYdd9yRV199laysLD777DP69+9Pbm4uL774Is888wzvv/8+2dnZLFu2DIABAwYwdOhQjj/+eFavXk1+fn56C2kz0jW88grgLjMbBLwJfA1sKOvK7j4aGA2Qk5PjaYpJRCrRggXlm741+vXrR82aNQFYsWIFAwcO5LPPPsPMWLduXYnrHHPMMdStW5e6deuy4447smjRIlq0aFFkmQMPPLBwWocOHZg/fz716tVj9913Lxy+2L9/f0aPHr3J9tetW8eFF17ItGnTqFmzJp9++ikAr732GmeeeSbZ2dkANG7cmJUrV/L1119z/PHHA2EsfFUqS9PN18BuKc9bRNMKufs37n6Cu3cErommLS/LuiKybSrt4LsyDsq33377wsfXXXcdhx9+ODNnzuTZZ58tdahh3bp1Cx/XrFmT9evXV2iZ0vz9739np512Yvr06eTm5m6xszhOZUn0U4A9zKyNmdUBTgEmpi5gZk3NrGBbVwMPRY9fBo4ys0Zm1gg4KpomItu4ESMgqrQWys4O0yvTihUraN48tACPGTMm7dvfa6+9+OKLL5g/fz4Ajz32WKlx7LLLLtSoUYOxY8eyYUNoxOjRowcPP/wwq6J2rWXLllG/fn1atGjB008/DcCaNWsK51eFLSZ6d18PXEhI0J8Aj7v7LDMbbma9o8W6A3PN7FNgJ2BEtO4y4EbCj8UUYHg0TUS2cQMGwOjR0KoVmIX/o0env32+uKuuuoqrr76ajh07lqsGXlbbbbcd99xzDz179qRz587Ur1+fhg0bbrLc+eefzyOPPEL79u2ZM2dO4VFHz5496d27Nzk5OXTo0IGRI0cCMHbsWEaNGsX+++9Ply5d+O6779Iee2msoJc5U+Tk5Hhubm7cYYhUS5988gl777133GHE7qeffqJevXq4OxdccAF77LEHl156adxhFSrpfTKzqe6eU9LyOjNWRKSY+++/nw4dOrDvvvuyYsUKzjnnnLhD2iq6qJmISDGXXnppRtXgt5Zq9CIiCadELyKScEr0IiIJp0QvIpJwSvQikjEOP/xwXn656DmVd9xxB+edd16p63Tv3p2CIdm9evVi+fLlmywzbNiwwvHspXn66aeZPXt24fPrr7+e1157rTzhZywlehHJGP3792fChAlFpk2YMKHUC4sV98ILL7DDDjtUaN/FE/3w4cM58sgjK7StTKNELyIZo2/fvjz//POF142ZP38+33zzDd26deO8884jJyeHfffdlxtuuKHE9Vu3bs2SJUsAGDFiBHvuuSeHHnpo4aWMIYyRP+CAA2jfvj0nnngiq1at4t1332XixIlceeWVdOjQgc8//5xBgwbx5JNPAjBp0iQ6duxIu3btOOuss1izZk3h/m644QY6depEu3btmDNnziYxZcLljDWOXkRKdMklMG1aerfZoQPccUfp8xs3bsyBBx7Iiy++SJ8+fZgwYQInnXQSZsaIESNo3LgxGzZs4IgjjmDGjBnsv//+JW5n6tSpTJgwgWnTprF+/Xo6depE586dATjhhBMYPHgwANdeey0PPvggF110Eb179+bYY4+lb9++Rba1evVqBg0axKRJk9hzzz0544wzuPfee7nkkksAaNq0KR9++CH33HMPI0eO5IEHHiiyfiZczlg1ehHJKKnNN6nNNo8//jidOnWiY8eOzJo1q0gzS3FvvfUWxx9/PNnZ2TRo0IDevXsXzps5cybdunWjXbt2jB8/nlmzZm02nrlz59KmTRv23HNPAAYOHMibb75ZOP+EE04AoHPnzoUXQku1bt06Bg8eTLt27ejXr19h3GW9nHF28SvHVYBq9CJSos3VvCtTnz59uPTSS/nwww9ZtWoVnTt35ssvv2TkyJFMmTKFRo0aMWjQoFIvT7wlgwYN4umnn6Z9+/aMGTOGyZMnb1W8BZc6Lu0yx6mXM87Pz6/ya9GDavQikmHq1avH4YcfzllnnVVYm//xxx/ZfvvtadiwIYsWLeLFF1/c7DYOO+wwnn76aX755RdWrlzJs88+Wzhv5cqV7LLLLqxbt47xKfc9rF+/PitXrtxkW3vttRfz589n3rx5QLgK5W9+85syv55MuJyxEr2IZJz+/fszffr0wkTfvn17OnbsSNu2bTn11FPp2rXrZtfv1KkTJ598Mu3bt+foo4/mgAMOKJx34403ctBBB9G1a1fatm1bOP2UU07htttuo2PHjkU6QLOysnj44Yfp168f7dq1o0aNGpx77rllfi2ZcDljXaZYRArpMsXbBl2mWEREilCiFxFJOCV6EZGEU6IXkSIyrd9OiqrI+6NELyKFsrKyWLp0qZJ9hnJ3li5dWu6x+DphSkQKtWjRgry8PBYvXhx3KFKKrKwsWrRoUa51lOhFpFDt2rVp06ZN3GFImqnpRkQk4ZToRUQSToleRCThlOhFRBJOiV5EJOGU6EVEEk6JXkQk4ZToRUQSToleRCThlOhFRBJOiV5EJOGU6EVEEk6JXkQk4ZToRUQSToleRCThypTozaynmc01s3lmNrSE+S3N7A0z+8jMZphZr2h6azP7xcymRX//L90vQERENm+LNx4xs5rA3UAPIA+YYmYT3X12ymLXAo+7+71mtg/wAtA6mve5u3dIb9giIlJWZanRHwjMc/cv3H0tMAHoU2wZBxpEjxsC36QvRBER2RplSfTNgYUpz/OiaamGAaeZWR6hNn9Ryrw2UZPOf82sW0k7MLMhZpZrZrm6V6WISHqlqzO2PzDG3VsAvYCxZlYD+BZo6e4dgcuAR82sQfGV3X20u+e4e06zZs3SFJKIiEDZEv3XwG4pz1tE01KdDTwO4O7/A7KApu6+xt2XRtOnAp8De25t0CIiUnZlSfRTgD3MrI2Z1QFOASYWW2YBcASAme1NSPSLzaxZ1JmLme0O7AF8ka7gM1V+ftwRiIhstMVE7+7rgQuBl4FPCKNrZpnZcDPrHS12OTDYzKYD/wIGubsDhwEzzGwa8CRwrrsvq4wXkinuuw8aN4a33oo7EhGRwEI+zhw5OTmem5sbdxgVcvfdcOGFYAb77Qcffgi1tjiAVURk65nZVHfPKWmezoxNkzvvDEm+Tx949FH4+GO49964oxIRUaJPi9tvh0sugRNOgMcfh5NPhh494Lrr4Pvv445ORKo7JfqtdOutcPnl0K8fTJgAdeqEpptRo+Dnn+FPf4o7QhGp7pTot8LNN8Mf/winnBKaa2rX3jivbdtQy3/oIfjgg/hiFBFRoq+g4cPhmmvgtNNg7NiSO12vuw522im03WvIpYjERYm+nNzh+uvhhhtg4EAYM6b0kTUNGoSmnSlTwnIiInFQoi8Hd7j2WrjxRjj77NAsU7Pm5tc57TTo0gWGDoXly6smThGRVEr0ZeQekvXNN8OQITB6NNQoQ+mZwV13wZIlMGxYpYcpIrIJJfoycIcrrgjNMOefH8bHlyXJF+jYEc45JyT8mTMrL04RkZIo0W+Bexg9c/vtcPHFIVmXJ8kXuOkmaNgQLroobFNEpKoo0W9Gfn4YMTNqFFx6KdxxR2iKqYgmTWDECJg8GZ54Iq1hiohslhJ9KfLzQzPNPffAlVfC3/5W8SRfYPDg0Ixz+eXhZKrqYN06+OmnuKMQqd6U6EuQnx86XO+7D66+Gv76161P8hBG6PzjH5CXFzp1k27DBjj22HA0078/vP66zicQiYMSfTEbNoShkw8+GE54GjEiPUm+QNeuYcjlyJEwb176tpuJrrsOXnkFevWCl1+GI46APfeEW26Bb7+NOzqJ28qV8NRT4b9ULiX6FBs2wKBB4eSmP/85nP2aziRf4NZbwzVxLr00/dvOFE8/HRL64MHwn//AN9/A+PHQsmW4/s9uu8Fxx8Fzz8H69XFHK1VtwYJQ6enbF5o3D31hs2fHHVWCuXtG/XXu3NnjsG6de//+7uB+002Vv7/bbgv7eu65yt9XVZs7171BA/ecHPdfftl0/qefug8d6r7TTqEMmjd3v/Za9y++qPpYpeq9/3547xs0cB892v30093r1AmfhcMPd3/yyfB9lPIBcr2UvBp7Yi/+F0eiX7vWvV+/UBp/+UvV7HPNGve99nL/9a/dV6+umn1WhZ9+ct93X/cmTdznz9/8smvXuv/nP+69ernXqOFu5t6jh/tjjyWrTGSjJ55wz8pyb9PGfdasjdO//979llvcW7bc+OM/fLj7t9/GF+u2Rol+M9ascT/hhFASI0dW6a795ZfDfm++uWr3W1ny88NRkZn7K6+Ub90FC9z//OeNX/SmTd0vu8x99uzKiVWqVn5++JyDe5cuIbGXZP1692eecT/qqLBs7drup5zi/tZbYRtSOiX6UqxZ496nTyiFO+6ost0Wcfzx7tnZIdFt6+68M5TliBEV38b69e4vveTet697rVphe127uo8Z4/7zz+mLNQ4bNoT3ubo1S6xZ4z5wYHgvTz215Oa8ksyd637JJe4NG4Z199/f/b77wlGjbEqJvgSrV7sfe2wogbvuqpJdlujLL8Oh7MknxxdDOrz1VkjMvXuHhJYOixaFvow99wzvU4MG7ued5z51anq2X5lWrXL/4IPQBn3BBeHHql698Do6dizabJFkS5a4H3ZYeN3DhlWsVv7TT6Ec27cP22nY0P0Pfwg/BLKREn0xv/zifvTR4dXfe2+l726Lhg0LsbzxRtyRVMy337rvskvob/jhh/RvPz/f/c03Q6ddVlYoq06d3O+5x3358vTvr7wWLQrNcH/9a2i62mef0OcQLnbhXr++e7du7hdeGPqAmjZ1r1s3HEWm60cxE82dGz4Tdeq4jx+/9dvLz3d/++1QxrVrh7I96qjQ1LN+/dZvf1unRJ9i1arw4TBzv//+St1Vma1a5d66tft++217h/Vr14Ya23bbuc+YUfn7++GHcARWULvbbrvQLPD225Xfhrt+vfucOe4TJoRRQz17hh+4goQOoY+hd2/36693f+op988/3zSZf/fdxqPJI45wX7iwcuOOwxtvuDdqFH7U3n47/dv/9tvQWdu8eSjHVq1CZ25pbf/VgRJ95OefwxfLzP2hhyptNxXy73+Hd+POO+OOpHwuuyzEPW5c1e43P999yhT3c84JNWZw33tv97/9LT1f9p9+cv/f/8IR3znnuB90UOhLKUjotWuHH5uBA93//nf31193X7q0fPGPHu2+/fbuO+zg/uijWx9zpnjoodCMt/fe4YeuMq1bF4ZjHn54eF/q1AlHfu+9V/06b5XoPXxxu3cPh9T//Gel7GKr5OeHoYUNG4amgG3BY4+FT9BFF8Ubx8qVIbkccsjGJHzSSWHkz5aaRvLz3b/+2v2FF8KokJNOCn0CZhuTeqNG4bNzySWhU3jatNDBmA6ffbYx7lNOKd+PRabZsMH9j38Mr6VHj8ppxtucWbNCf0hBXwop8/IAAAzASURBVEjnzuFzsWpV1cYRl2qf6H/8MbSR1qiRnrbCyvLJJ6EmdPbZcUeyZbNmhdpoly7pS3rpMHNmSMiNG4dPd+vW7jfe6J6XF2p/M2eGz8CVV4Zk1KyZF2l62X33MBLqz38Obb9ffVX5NcN168JJerVqhaaI8g5NzQQ//7xxmPI554Qmvbj8+KP73XeHvhIIn4Urrqj8o4u4VetEv2JFGPFQs2ZoW810V1wR3pX33487ktKtWBFO9tppp1AbzkSrV7v/61+hqQ7Cj3xBRy6EztDOnd3POst91KjQ2Rt3x25ubmjuKDhK2laGk37zTTgL2sz99tszp8kkPz/0FfTtG77/ZuHkvOefT2YneLVN9MuXux98cKgpPflk2jZbqVascN95Z/cDDsjMD2N+fqi51azpPnly3NGUzbx5oXP08svdx451//jjeGucm7NqVRg6CO5t24bkn8mmTXPfbbdwdPfMM3FHU7q8vPAZ2HnnjUdut922bTeVFVctE/2yZSFZ1q4dTrPflowdG96ZBx+MO5JN3Xqrx3IWcXXz6quhGadWrdD0lImjsZ57LrSHN2/u/tFHcUdTNmvWhCP7bt3C5zgry/3MM93feSezmiArotol+qVLwzjrOnXcJ07c6s1Vufz80NzUrFnVd2htzqRJoQmkb9/MOTxPsmXLNl5o7+CDQ8dtJsjPD+cA1KgRmr8ytfluS6ZPdx8yZONoqrp1Q5/TZZe5P/54OIt5W/qcV6tEv3ixe4cO4U17/vmt2lSsPvwwtClefHHckQQLF4YfnrZtQ2eXVJ1HHw1DMLOzwyUA4kw+69a5n39+yBzHHZeMyxH88EO42Nrll4cKVmpfzq67hqbKW28N/TiZ3G9SbRL999+7t2sXkvxLL1V4Mxnj3HNDW/jHH8cbx+rVYRx5vXq6yFhcFi7c2LF8zDHxXNVx+XL33/0uxHDVVZnZh5QOa9aEczT+8Q/3AQPcf/WrjYm/Zs3QWnD++WGY9qefZk6tv1ok+kWLwuVxs7JC+2YSLFkShoZ17x7vh6mgBvfEE/HFICGx3nln+Iw3bRpOsqsqX34ZhivWquX+wANVt99M8f337s8+637NNeEHt+AkvYLhm716hTN1X3klvtFb1SLRL10aDrsmTarQ6hnr3nvDuxTX0NBHHgn7v+KKePYvm5o1K9QqIXQkrlhRuft79133HXcMzUdJ+35V1Pr14Uj7/vvDeS/77rvxJDuz8KN41lnh7OcZM6rmWjybS/QW5meOnJwcz83NrdC67pVz6784bdgABxwAixfDnDmw/fZVt+9p0+CQQ+Dgg+HVV6FWrarbt2ze2rXhVpe33BJuz/jII3DYYenfz4QJ4faaLVqE2z62bZv+fSTFihUwZQq8997Gv6VLw7x69eDAA8N36eCD4aCDYMcd07t/M5vq7jklzktSok+qd96BQw8N91odMaJq9vnDD5CTA6tXw4cfwk47Vc1+pXzefRfOOAO++AKuvDIk/7p1t3677nDTTXD99dCtG/z739C06dZvtzpxh88/L5r4p0/feI/k3XffmPgPPhjatw/3kq6ozSX62Jtqiv/Fdc/YTFdwX82qGGK3YUPo8KtdOxy2S2ZbuTIMEyy4OcfWXkV09Wr3004L2zv9dN3WMZ1+/jncu+G229xPPDGM6kk9W/vEEyu+bapDG33SffNN6AA65pjK39fw4R77DVmk/J59NrSl16kTTmiryKiYxYvdDz00vP833ZQ5I0qSbOHCjcM7r7uu4ttRok+I224L79hzz1XePl56KXQmnXaavuTbou+/D+PbIYzW2tIN2lN98km4NEBWVrgyqWxbNpfoa5Sx7aenmc01s3lmNrSE+S3N7A0z+8jMZphZr5R5V0frzTWz31Ws9UkALr44dIb94Q+h7Tzd5s+HU0+Fdu3gvvuS17FdHTRrFtrTH3oIcnNh//1h7NjQOLA5kyaFduKffoLJk+Gkk6okXKkiW0z0ZlYTuBs4GtgH6G9m+xRb7FrgcXfvCJwC3BOtu0/0fF+gJ3BPtD2pgDp1YNSo0MFz++3p3fbq1XDiiWGUz1NPQXZ2ercvVccMzjwTZswIif6MM0LiLhgBUtz990PPnrDbbvD++2FEiCRLWWr0BwLz3P0Ld18LTAD6FFvGgQbR44bAN9HjPsAEd1/j7l8C86LtSQX16AHHHx9G3yxcmL7tXnhhGF0zdiz8+tfp267Ep02bUDv/y1/gmWdgv/3gpZc2zt+wIYzUGTIEjjwyjO5q3TquaKUylSXRNwdSU0peNC3VMOA0M8sDXgAuKse6mNkQM8s1s9zFixeXMfTq6/bbIT8/fEnT4YEH4MEH4dpr4fe/T882JTPUrAl//CN88AE0aQJHHw3nnw/ffx+O4EaODD/yzz4LDRpseXuybSpTG30Z9AfGuHsLoBcw1szKvG13H+3uOe6e06xZszSFlFytW8PQofDYY6HGtjWmTIELLoCjjoJhw9IQnGSkDh1Cm/1ll8G990Lz5iG5jxoF//iHToZLurIk46+B3VKet4impTobeBzA3f8HZAFNy7iuVMBVV4WEf9FFG0/AKK8lS6BvX9h5Z3j00VD7k+TKyoK//Q1efz2cBPXss+HzI8lXlkQ/BdjDzNqYWR1C5+rEYsssAI4AMLO9CYl+cbTcKWZW18zaAHsAH6Qr+Opsu+1CE87MmXDPPeVff8OGMMLmu+9C52uTJumPUTLT4YeHZN+r15aXlWTYYqJ39/XAhcDLwCeE0TWzzGy4mfWOFrscGGxm04F/AYOioZ2zCDX92cBLwAXuvqEyXkh1dNxxocnl+utDm2t53HBDuH7N3XeHSx2ISHLpWjfbuDlzwrj3M84IHaplMXEi9OkDZ58dOmJFZNu3uWvdpKszVmLSti1cckk4QeaDMjSKffYZnH46dO4Md91V+fGJSPyU6BPguutgl13CMLn8/NKX+/nnMKSuVi148snQOSciyadEnwANGsCtt4ahkmPGlLyMezgxZubMMMJGJ8aIVB9K9AkxYAB07RrG1y9fvun8u+8OCX74cPidrjgkUq0o0SeEWTjxZcmSMKIm1bvvwqWXwrHHhpuXiEj1okSfIB07wrnnhtr7xx+HaYsWQb9+0KpVuI5NDb3jItWOvvYJc+ON0LBhOONx3To4+eRwW8CnnoIddog7OhGJgxJ9wjRpEq5s+d//hjMg//tfGD063I9SRKonJfoEGjw4NOO88064YNlpp8UdkYjESdesS6CaNWHcuDDK5vrr445GROKmRJ9Q++wDN90UdxQikgnUdCMiknBK9CIiCadELyKScEr0IiIJp0QvIpJwSvQiIgmnRC8iknBK9CIiCZdx94w1s8XAV3HHsZWaAkviDiKDqDyKUnlspLIoamvKo5W7NytpRsYl+iQws9zSbtJbHak8ilJ5bKSyKKqyykNNNyIiCadELyKScEr0lWN03AFkGJVHUSqPjVQWRVVKeaiNXkQk4VSjFxFJOCV6EZGEU6JPIzPbzczeMLPZZjbLzP4Qd0xxM7OaZvaRmT0XdyxxM7MdzOxJM5tjZp+Y2SFxxxQnM7s0+p7MNLN/mVlW3DFVJTN7yMy+N7OZKdMam9mrZvZZ9L9ROvalRJ9e64HL3X0f4GDgAjPbJ+aY4vYH4JO4g8gQdwIvuXtboD3VuFzMrDlwMZDj7vsBNYFT4o2qyo0BehabNhSY5O57AJOi51tNiT6N3P1bd/8weryS8EVuHm9U8TGzFsAxwANxxxI3M2sIHAY8CODua919ebxRxa4WsJ2Z1QKygW9ijqdKufubwLJik/sAj0SPHwGOS8e+lOgriZm1BjoC78cbSazuAK4C8uMOJAO0ARYDD0dNWQ+Y2fZxBxUXd/8aGAksAL4FVrj7K/FGlRF2cvdvo8ffATulY6NK9JXAzOoBTwGXuPuPcccTBzM7Fvje3afGHUuGqAV0Au51947Az6TpsHxbFLU99yH8AO4KbG9mp8UbVWbxMPY9LePflejTzMxqE5L8eHf/d9zxxKgr0NvM5gMTgN+a2bh4Q4pVHpDn7gVHeE8SEn91dSTwpbsvdvd1wL+BLjHHlAkWmdkuANH/79OxUSX6NDIzI7TBfuLut8cdT5zc/Wp3b+HurQmdbK+7e7Wtsbn7d8BCM9srmnQEMDvGkOK2ADjYzLKj780RVOPO6RQTgYHR44HAM+nYqBJ9enUFTifUXqdFf73iDkoyxkXAeDObAXQAbo45nthERzZPAh8CHxNyUbW6HIKZ/Qv4H7CXmeWZ2dnAX4AeZvYZ4ajnL2nZly6BICKSbKrRi4gknBK9iEjCKdGLiCScEr2ISMIp0YuIJJwSvYhIwinRi4gk3P8HX34d2ZuI1hAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Train fold with 16810 images\n",
      "label\n",
      "covid        6970\n",
      "non covid    9840\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Validation fold with 4756 images\n",
      "label\n",
      "covid        1968\n",
      "non covid    2788\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "axis2\n",
      "=====\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 448, 448, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 454, 454, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 224, 224, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 224, 224, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 224, 224, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 226, 226, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 112, 112, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 112, 112, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 112, 112, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 112, 112, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 112, 112, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 112, 112, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 112, 112, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 112, 112, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 112, 112, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 112, 112, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 112, 112, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 112, 112, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 112, 112, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 112, 112, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 112, 112, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 112, 112, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 112, 112, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 112, 112, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 112, 112, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 112, 112, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 56, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 56, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 56, 56, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 56, 56, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 56, 56, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 56, 56, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 56, 56, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 56, 56, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 56, 56, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 56, 56, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 56, 56, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 56, 56, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 56, 56, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 56, 56, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 56, 56, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 56, 56, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 56, 56, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 56, 56, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 56, 56, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 56, 56, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 56, 56, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 56, 56, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 56, 56, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 28, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 28, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 28, 28, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 28, 28, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 28, 28, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 28, 28, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 28, 28, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 28, 28, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 28, 28, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 28, 28, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 28, 28, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 28, 28, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 28, 28, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 28, 28, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 28, 28, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 28, 28, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 28, 28, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 28, 28, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 28, 28, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 28, 28, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 28, 28, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 28, 28, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 28, 28, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 28, 28, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 28, 28, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 28, 28, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 28, 28, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 28, 28, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 28, 28, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 28, 28, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 28, 28, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 28, 28, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 28, 28, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 28, 28, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 28, 28, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 28, 28, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 28, 28, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 28, 28, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 28, 28, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 28, 28, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 28, 28, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 28, 28, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 28, 28, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 28, 28, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 28, 28, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 28, 28, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 28, 28, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 28, 28, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 28, 28, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 28, 28, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 28, 28, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 28, 28, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 28, 28, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 28, 28, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 28, 28, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 28, 28, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 28, 28, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 28, 28, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 28, 28, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 28, 28, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 28, 28, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 28, 28, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 28, 28, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 28, 28, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 28, 28, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 28, 28, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 28, 28, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 28, 28, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 28, 28, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 28, 28, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 28, 28, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 28, 28, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 28, 28, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 28, 28, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 28, 28, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 14, 512)  524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 14, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 14, 14, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 14, 14, 2048) 2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 14, 14, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 14, 14, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 14, 14, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 14, 14, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 14, 14, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 14, 14, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 14, 14, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 14, 14, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 14, 14, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 14, 14, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 14, 14, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 14, 14, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 14, 14, 2048) 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         1049600     dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            2050        batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 45,812,098\n",
      "Trainable params: 45,704,706\n",
      "Non-trainable params: 107,392\n",
      "__________________________________________________________________________________________________\n",
      "Found 16810 validated image filenames belonging to 2 classes.\n",
      "Found 4756 validated image filenames belonging to 2 classes.\n",
      "{'covid': 0, 'non covid': 1}\n",
      "{'covid': 0, 'non covid': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.9224\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87942, saving model to training/20201029//resnet101v2/fold5/axis2//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold5/axis2//my_checkpoint/assets\n",
      "2101/2101 [==============================] - 2509s 1s/step - loss: 0.1891 - accuracy: 0.9224 - val_loss: 0.4325 - val_accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9790\n",
      "Epoch 00002: val_accuracy did not improve from 0.87942\n",
      "2101/2101 [==============================] - 2473s 1s/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.4345 - val_accuracy: 0.8617\n",
      "Epoch 3/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9875\n",
      "Epoch 00003: val_accuracy improved from 0.87942 to 0.90614, saving model to training/20201029//resnet101v2/fold5/axis2//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold5/axis2//my_checkpoint/assets\n",
      "2101/2101 [==============================] - 2507s 1s/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.3268 - val_accuracy: 0.9061\n",
      "Epoch 4/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9883\n",
      "Epoch 00004: val_accuracy did not improve from 0.90614\n",
      "2101/2101 [==============================] - 2473s 1s/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.4528 - val_accuracy: 0.8653\n",
      "Epoch 5/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9923\n",
      "Epoch 00005: val_accuracy did not improve from 0.90614\n",
      "2101/2101 [==============================] - 2475s 1s/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.6161 - val_accuracy: 0.8516\n",
      "Epoch 6/10\n",
      "2101/2101 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9937\n",
      "Epoch 00006: val_accuracy improved from 0.90614 to 0.91982, saving model to training/20201029//resnet101v2/fold5/axis2//my_checkpoint\n",
      "INFO:tensorflow:Assets written to: training/20201029//resnet101v2/fold5/axis2//my_checkpoint/assets\n",
      "2101/2101 [==============================] - 2508s 1s/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.3581 - val_accuracy: 0.9198\n",
      "Epoch 7/10\n",
      "1709/2101 [=======================>......] - ETA: 7:01 - loss: 0.0150 - accuracy: 0.9946"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, 1))\n",
    "labels = data_train['covid'].unique()\n",
    "\n",
    "labels.sort()\n",
    "labels_length = len(labels)\n",
    "labels_pos_dict = dict(zip(labels, [i for i in range(labels_length)]))\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    \n",
    "    ''' CREATE PATHS FOR SAVE OUTPUT '''\n",
    "    predicted_dir = \"{}/\".format(OUTPUT_PREDICTED_FOLDER)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    predicted_dir = \"{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    ''''''\n",
    "    \n",
    "    ''' CREATE DATAFRAME AND CONFUSION MATRIX - ACCUMULATED '''\n",
    "    # Predicted class for patient and fold\n",
    "    df_axis = pd.DataFrame(columns=['fold', 'patient', 'real', 'predicted', 'count'])\n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix = np.zeros(labels_length*labels_length).reshape(labels_length, labels_length)\n",
    "    ''''''\n",
    "    \n",
    "    for n_fold in [4, 5]:\n",
    "#     for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_train = pd.read_csv(\"{}/train/train{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        train_df, validation_df = get_data_set(n_fold, axis, data_train, data_validation)\n",
    "        data_validation_dict = dict(zip(data_validation.nome, data_validation.covid))\n",
    "        \n",
    "        print('\\n'+axis+'\\n=====')\n",
    "        model, SELECTED_MODEL = get_model_resnet101v2()\n",
    "        history = train_model(model, train_df, validation_df, EPOCHS, n_fold, axis)\n",
    "        \n",
    "        #Plot Results\n",
    "        plot_results(history, axis, n_fold, SELECTED_MODEL)\n",
    "        # Load legend\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        \n",
    "        \n",
    "#         '''  GET DATA  '''\n",
    "#         # Test with other patients\n",
    "#         df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)\n",
    "#         idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "#         df = df[idx]\n",
    "#         df.reset_index(drop=True, inplace=True)\n",
    "#         df['fold'] = n_fold\n",
    "#         df['real'] = ''\n",
    "#         last_patient = ''\n",
    "        \n",
    "#         for index, row in df.iterrows():\n",
    "#             if row['patient'] != last_patient:\n",
    "#                 df.loc[index, 'real'] = data_validation_dict[row['patient']]\n",
    "#                 real_label_pos = labels_pos_dict[data_validation_dict[row['patient']]]\n",
    "#                 pred_label_pos = labels_pos_dict[row['predicted']]\n",
    "#                 confusion_matrix[real_label_pos][pred_label_pos] += 1\n",
    "#             last_patient = row['patient']        \n",
    "#         df_axis = df_axis.append(df)\n",
    "#         '''''' '''''' ''''''\n",
    "        \n",
    "#     predicted_dir = \"{}/{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis, SELECTED_MODEL)\n",
    "#     if not os.path.exists(predicted_dir): \n",
    "#         os.mkdir(predicted_dir)\n",
    "#     df_axis.to_csv(predicted_dir+'predicted.csv', index=False)\n",
    "#     print(labels_pos_dict)\n",
    "#     print(confusion_matrix)\n",
    "    \n",
    "#     '''\n",
    "#     PRINT METRICS AND CONFUSION MATRIX\n",
    "#     '''\n",
    "#     pm.plot_labels_metrics(cm=confusion_matrix, normalize=False, labels=labels, show_zero=False,\n",
    "#                 title='Metrics', clear_diagonal=False, figsize=(15, 105), output_file=\"metrics.png\"\n",
    "#                           )\n",
    "#     pm.plot_confusion_matrix(cm=confusion_matrix, normalize=False, labels=labels, show_zero=False,\n",
    "#                 title=\"Confusion Matrix\", clear_diagonal=False, output_file=\"matrix.png\", figsize=(10, 7)\n",
    "#                             )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models!\n",
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HMV + HCPA\n",
    "'''\n",
    "data_train = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, 1))\n",
    "labels = data_train['covid'].unique()\n",
    "\n",
    "labels.sort()\n",
    "labels_length = len(labels)\n",
    "labels_pos_dict = dict(zip(labels, [i for i in range(labels_length)]))\n",
    "\n",
    "\n",
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=======================================================================================')\n",
    "    \n",
    "    predicted_dir = \"{}/\".format(OUTPUT_PREDICTED_FOLDER)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    predicted_dir = \"{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    \n",
    "    \n",
    "    # Predicted class for patient and fold\n",
    "    df_axis = pd.DataFrame(columns=['fold', 'patient', 'real', 'predicted', 'count'])\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix = np.zeros(labels_length*labels_length).reshape(labels_length, labels_length)\n",
    "\n",
    "#     for n_fold in [1, 2, 3, 4, 5]: \n",
    "    for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))\n",
    "        \n",
    "        data_validation = pd.read_csv(\"{}/test/test{}.csv\".format(STRUCTURE_DATASET_FOLDER, n_fold))\n",
    "        \n",
    "        data_validation_dict = dict(zip(data_validation.nome, data_validation.covid))\n",
    "        \n",
    "        model, SELECTED_MODEL = get_model_resnet101v2()\n",
    "        legend_path = \"{}/{}/fold{}/{}/legend\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis)\n",
    "        \n",
    "        model = tf.keras.models.load_model(\"{}/{}/fold{}/{}/my_checkpoint\".format(TRAINING_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        \n",
    "        # Test with other patients\n",
    "        df = predictions_by_patient(model, data_validation['nome'].to_list(), legend_path, axis)\n",
    "        idx = df.groupby(['patient'])['count'].transform(max) == df['count']\n",
    "        df = df[idx]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df['fold'] = n_fold\n",
    "        df['real'] = ''\n",
    "        last_patient = ''\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            if row['patient'] != last_patient:\n",
    "                df.loc[index, 'real'] = data_validation_dict[row['patient']]\n",
    "                real_label_pos = labels_pos_dict[data_validation_dict[row['patient']]]\n",
    "                pred_label_pos = labels_pos_dict[row['predicted']]\n",
    "                confusion_matrix[real_label_pos][pred_label_pos] += 1\n",
    "            last_patient = row['patient']        \n",
    "        df_axis = df_axis.append(df)\n",
    "        del model\n",
    "        \n",
    "    predicted_dir = \"{}/{}/{}/\".format(OUTPUT_PREDICTED_FOLDER, axis, SELECTED_MODEL)\n",
    "    if not os.path.exists(predicted_dir): \n",
    "        os.mkdir(predicted_dir)\n",
    "    df_axis.to_csv(predicted_dir+'predicted.csv', index=False)\n",
    "    print(labels_pos_dict)\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    '''\n",
    "    PRINT METRICS AND CONFUSION MATRIX\n",
    "    '''\n",
    "    pm.plot_labels_metrics(\n",
    "                cm=confusion_matrix,\n",
    "                normalize=False,\n",
    "                labels=labels,\n",
    "                show_zero=False,\n",
    "                title='Metrics - ' + axis,\n",
    "                clear_diagonal=False,\n",
    "                figsize=(15, 105),\n",
    "                output_file=\"metrics.png\"\n",
    "            )\n",
    "    pm.plot_confusion_matrix(\n",
    "                cm=confusion_matrix,\n",
    "                normalize=False,\n",
    "                labels=labels,\n",
    "                show_zero=False,\n",
    "                title=\"Confusion Matrix - \" + axis,\n",
    "                clear_diagonal=False,\n",
    "                output_file=\"matrix.png\",\n",
    "                figsize=(10, 7)\n",
    "#                 verbose=args.verbose,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for axis in SUB_FILE:\n",
    "    print('\\n'+axis+'\\n=====')\n",
    "    for n_fold in [j+1 for j in range(5)]:\n",
    "        print(\"\\n\\n\\nFold\", str(n_fold))        \n",
    "        #model, SELECTED_MODEL = get_model_resnet50()\n",
    "        SELECTED_MODEL = 'vgg16'\n",
    "        df = pd.read_csv(\"{}/{}/fold{}/{}/history.csv\".format(MODEL_FOLDER, SELECTED_MODEL, n_fold, axis))\n",
    "        print(max(df['val_accuracy']))\n",
    "        print((df['val_accuracy'].mean()))\n",
    "#         print(df['val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
